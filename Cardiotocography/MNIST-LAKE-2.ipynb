{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GPU acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the GPU acceleration properly up on Pytorch for a .ipynb file on Axon. <br>\n",
    "You have to first use nvidia-smi to see an unused GPU,  <br>\n",
    "then use nvidia-smi -L to see its MIG ID, and set it as an environmental variable.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for the CUDA_VISIBLE_DEVICES value\n",
    "cuda_device = input(\"Enter the CUDA_VISIBLE_DEVICES value: \")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cuda_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(\"Is CUDA available:\", is_cuda_available)\n",
    "\n",
    "# Determine the device to use: GPU (CUDA), Apple Silicon (MPS), or CPU\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tensor on CUDA: tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Test tensor operation on GPU\n",
    "    test_tensor = torch.tensor([1.0, 2.0, 3.0], device=\"cuda\")\n",
    "    print(\"Test tensor on CUDA:\", test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully moved a tensor to the device: tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if is_cuda_available:\n",
    "    try:\n",
    "        test_tensor = torch.tensor([1, 2, 3], device=DEVICE)\n",
    "        print(\"Successfully moved a tensor to the device:\", test_tensor)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error moving a tensor to the device:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining VAE classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20, w_dim=10):\n",
    "        super(StandardVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder layers\n",
    "        # Input: [bs, 1, 28, 28]\n",
    "        self.enc_conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)  # Output: [bs, 16, 14, 14]\n",
    "        self.enc_conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1) # Output: [bs, 32, 7, 7]\n",
    "        self.enc_fc1 = nn.Linear(32 * 7 * 7, w_dim)  # Output: [bs, 128]\n",
    "        # Two output layers for the latent space\n",
    "        self.enc_fc2 = nn.Linear(w_dim, latent_dim)  # For mu, Output: [bs, latent_dim]\n",
    "        self.enc_fc3 = nn.Linear(w_dim, latent_dim)  # For logvar, Output: [bs, latent_dim]\n",
    "\n",
    "        # Decoder layers\n",
    "        self.dec_fc1 = nn.Linear(latent_dim, w_dim)  # Output: [bs, 128]\n",
    "        self.dec_fc2 = nn.Linear(w_dim, 32 * 7 * 7)  # Output: [bs, 1568]\n",
    "        self.dec_conv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: [bs, 16, 14, 14]\n",
    "        self.dec_conv2 = nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: [bs, 1, 28, 28]\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.enc_conv1(x))\n",
    "        h = F.relu(self.enc_conv2(h))\n",
    "        h = torch.flatten(h, start_dim=1)\n",
    "        h = F.relu(self.enc_fc1(h))\n",
    "        return self.enc_fc2(h), self.enc_fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        # Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.dec_fc1(z)) \n",
    "        h = F.relu(self.dec_fc2(h)).view(-1, 32, 7, 7) # .view reshapes [bs, 1568] to [bs, 32, 7, 7]\n",
    "        h = F.relu(self.dec_conv1(h))\n",
    "        return torch.sigmoid(self.dec_conv2(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), z, mu, logvar\n",
    "\n",
    "def loss_function_standard(recon_x, z, mu, logvar, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Can reweight BCE + KLD as desired\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LakeVAE inheirits from StandardVAE, but with a modified forward pass.\n",
    "Its encoding and decoding layers are identicle. \n",
    "The only difference is that the forward pass stores and returns all the intermediate values required to calculate the modified reconstruction loss.\n",
    "\n",
    "Since pixel values are either 0 or 1, we can use BCE between the input image and output image.\n",
    "However, for the intermediate layers, that are continuous, we use can MSE instead. This is also what the paper's code does in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LakeVAE(StandardVAE):\n",
    "    def forward(self, x):\n",
    "        # Encoder layers\n",
    "        # Input: [bs, 1, 28, 28]\n",
    "        enc_conv1_out = F.relu(self.enc_conv1(x))  # Output: [bs, 16, 14, 14]\n",
    "        enc_conv2_out = F.relu(self.enc_conv2(enc_conv1_out))  # Output: [bs, 32, 7, 7]\n",
    "        flattened = torch.flatten(enc_conv2_out, start_dim=1)  # Output: [bs, 1568]\n",
    "        \n",
    "        # w = F.relu(self.enc_fc1(flattened))  # Output: [bs, 128] # Eqn (5) in LAKE paper\n",
    "        w = self.enc_fc1(flattened)  # Not sure if relu is used in the paper or not. Output: [bs, 128] # Eqn (5) in LAKE paper\n",
    "        \n",
    "        mu, logvar = self.enc_fc2(w), self.enc_fc3(w)  # Output: [bs, latent_dim], [bs, latent_dim] # Eqn (6) in LAKE paper\n",
    "\n",
    "        # Reparameterization and Decoding layers\n",
    "        z = self.reparameterize(mu, logvar)  # Output: [bs, latent_dim] # Eqn (7) in LAKE paper\n",
    "        dec_fc1_out = F.relu(self.dec_fc1(z))  # Output: [bs, 128]\n",
    "        dec_fc2_out = F.relu(self.dec_fc2(dec_fc1_out)).view(-1, 32, 7, 7)  # Output: [bs, 1568], then reshaped to [bs, 32, 7, 7]\n",
    "        dec_conv1_out = F.relu(self.dec_conv1(dec_fc2_out))  # Output: [bs, 16, 14, 14]\n",
    "        recon_x = torch.sigmoid(self.dec_conv2(dec_conv1_out))  # Output: [bs, 1, 28, 28]\n",
    "\n",
    "        return recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out\n",
    "\n",
    "def loss_function_lake(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # Layer-wise reconstruction loss\n",
    "    layer_loss = F.mse_loss(enc_conv1_out, dec_conv1_out) + F.mse_loss(enc_conv2_out, dec_fc2_out) + F.mse_loss(w, dec_fc1_out)\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD + layer_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definining Utility Classes for training and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, latent_vectors, folder=\"generated_images\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = model.decode(latent_vectors).cpu()\n",
    "    for i, img in enumerate(generated):\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "        plt.savefig(f\"{folder}/img_{epoch}_{i}.png\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, data_loader, device, num_samples=1000):\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encode(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            if len(latents) * data_loader.batch_size > num_samples:\n",
    "                break\n",
    "    \n",
    "    latents = np.concatenate(latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    latents_reduced = pca.fit_transform(latents)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(latents_reduced[:, 0], latents_reduced[:, 1], c=labels, cmap='viridis', s=2, alpha=0.6)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Latent Space (PCA-reduced)\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.show()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_processing = False\n",
    "def plot_losses_interactive(model, model_name, model_states, train_losses, val_losses, train_loader, val_loader, device, best_train_loss, best_val_loss):\n",
    "    global is_processing\n",
    "    epochs = len(train_losses)\n",
    "    fig = go.FigureWidget()\n",
    "\n",
    "    # Add traces for training and validation losses\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=train_losses, mode='lines+markers', name='Training Loss'))\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=val_losses, mode='lines+markers', name='Validation Loss'))\n",
    "\n",
    "    # Set layout for the plot\n",
    "    fig.update_layout(\n",
    "        title=f'Interactive {model_name} Training and Validation Loss',\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis_title='Loss',\n",
    "        width=800, height=600\n",
    "    )\n",
    "\n",
    "    # Function to update the image on clicking a point on the plot\n",
    "    def update_image(trace, points, selector):\n",
    "        global is_processing\n",
    "        if is_processing:\n",
    "            return\n",
    "        is_processing = True\n",
    "    \n",
    "        if points.point_inds:\n",
    "            epoch = points.point_inds[0]\n",
    "            model.load_state_dict(model_states[epoch])\n",
    "            model.eval()\n",
    "    \n",
    "            # Determine which dataloader and best loss to use based on which trace was clicked\n",
    "            if trace.name == 'Training Loss':\n",
    "                data_loader = train_loader\n",
    "                current_loss = train_losses[epoch]\n",
    "                best_loss = best_train_loss\n",
    "                loss_type = 'Training'\n",
    "            elif trace.name == 'Validation Loss':\n",
    "                data_loader = val_loader\n",
    "                current_loss = val_losses[epoch]\n",
    "                best_loss = best_val_loss\n",
    "                loss_type = 'Validation'\n",
    "\n",
    "            # Calculate loss as a percentage of the best loss\n",
    "            loss_percentage = (best_loss / current_loss) * 100\n",
    "\n",
    "            # Generate and display an image\n",
    "            data, _ = next(iter(data_loader))\n",
    "            data = data.to(device)\n",
    "            reconstructed_img = model(data)[0].cpu().squeeze()\n",
    "\n",
    "            if reconstructed_img.ndim == 3:  # If image has 3 dimensions, take the first one\n",
    "                reconstructed_img = reconstructed_img[0]\n",
    "\n",
    "            # Display information and the image\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(reconstructed_img.detach().numpy(), cmap='gray')\n",
    "            plt.title(f'{model_name} {loss_type} Loss\\nEpoch: {epoch + 1}\\nLoss: {current_loss:.4f} ({loss_percentage:.2f}% rel to best)')\n",
    "            plt.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            display(plt.gcf())\n",
    "            model.train()\n",
    "    \n",
    "        is_processing = False\n",
    "\n",
    "    # Attach the click handler to the plot\n",
    "    fig.data[0].on_click(update_image)  # For training loss\n",
    "    fig.data[1].on_click(update_image)  # For validation loss\n",
    "\n",
    "    # Display the plot\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_vae(model, val_loader, loss_function, device):\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = loss_function(*outputs, data)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify train_vae to instead to the probability density estimation training.\n",
    "I'm not sure how its training, or what this is doing, considering there's no updates to anything?\n",
    "write the functions for rec_euclidean and rec_cosine.\n",
    "The first thing the VAE classes return with their forward pass is their reconstructed images x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, val_loader, loss_function, optimiser, epochs, device, model_name, plot_interval=1):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model_states = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = loss_function(*outputs, data)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss = total_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = validate_vae(model, val_loader, loss_function, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Save the current model state\n",
    "        model_states.append(model.state_dict().copy())\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            best_epoch = epoch\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "\n",
    "        print(f'Saving {model_name} model at epoch {epoch+1}')\n",
    "        save_model(model, f'{model_name}_{epoch+1}.pth')\n",
    "        \n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model_path = f\"best_{model_name}_epoch_{best_epoch}.pth\"\n",
    "        save_model(model, model_path)\n",
    "        print(f\"Best {model_name} model saved as {model_path}\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    best_train_loss = min(train_losses)\n",
    "    best_val_loss = min(val_losses)\n",
    "    plot_losses_interactive(model, model_name, model_states, train_losses, val_losses, train_loader, val_loader, device, best_train_loss, best_val_loss)\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell loads in the mnist dataset into train, validation, and test dataloaders.\n",
    "While doing so, they are normalised to be [0,1] and turned into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Splitting the dataset into train and validation sets\n",
    "train_size = int(0.8 * len(mnist_trainset))\n",
    "validation_size = len(mnist_trainset) - train_size\n",
    "train_dataset, validation_dataset = random_split(mnist_trainset, [train_size, validation_size])\n",
    "\n",
    "# Download and load the test data\n",
    "test_dataset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "Standard_VAE = StandardVAE().to(DEVICE)\n",
    "Lake_VAE = LakeVAE().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters: batch_size=64, learning_rate=0.001, epochs=100\n",
      "Training Standard_VAE...\n",
      "Epoch 1, Training Loss: 216.63298744710286, Validation Loss: 186.9185244954427\n",
      "Saving Standard_VAE model at epoch 1\n",
      "Epoch 2, Training Loss: 174.41765334065755, Validation Loss: 163.65676192220053\n",
      "Saving Standard_VAE model at epoch 2\n",
      "Epoch 3, Training Loss: 159.54346567789713, Validation Loss: 156.08525419108074\n",
      "Saving Standard_VAE model at epoch 3\n",
      "Epoch 4, Training Loss: 154.21702128092448, Validation Loss: 152.24092138671875\n",
      "Saving Standard_VAE model at epoch 4\n",
      "Epoch 5, Training Loss: 151.63424127197266, Validation Loss: 150.68963724772135\n",
      "Saving Standard_VAE model at epoch 5\n",
      "Epoch 6, Training Loss: 150.0141619466146, Validation Loss: 148.87698071289063\n",
      "Saving Standard_VAE model at epoch 6\n",
      "Epoch 7, Training Loss: 148.69508521525066, Validation Loss: 148.07883365885417\n",
      "Saving Standard_VAE model at epoch 7\n",
      "Epoch 8, Training Loss: 147.77145233154297, Validation Loss: 147.31320817057292\n",
      "Saving Standard_VAE model at epoch 8\n",
      "Epoch 9, Training Loss: 146.95817606608074, Validation Loss: 146.63166748046876\n",
      "Saving Standard_VAE model at epoch 9\n",
      "Epoch 10, Training Loss: 146.36571536254883, Validation Loss: 146.11750146484374\n",
      "Saving Standard_VAE model at epoch 10\n",
      "Epoch 11, Training Loss: 145.80335098266602, Validation Loss: 145.85103658040364\n",
      "Saving Standard_VAE model at epoch 11\n",
      "Epoch 12, Training Loss: 145.41788624064128, Validation Loss: 145.6014795328776\n",
      "Saving Standard_VAE model at epoch 12\n",
      "Epoch 13, Training Loss: 144.99512973022462, Validation Loss: 144.71542622884115\n",
      "Saving Standard_VAE model at epoch 13\n",
      "Epoch 14, Training Loss: 144.68754249064128, Validation Loss: 144.6293016357422\n",
      "Saving Standard_VAE model at epoch 14\n",
      "Epoch 15, Training Loss: 144.37958308919272, Validation Loss: 144.34554337565103\n",
      "Saving Standard_VAE model at epoch 15\n",
      "Epoch 16, Training Loss: 144.07845701090494, Validation Loss: 143.9824989827474\n",
      "Saving Standard_VAE model at epoch 16\n",
      "Epoch 17, Training Loss: 143.86202871704103, Validation Loss: 144.19640897623697\n",
      "Saving Standard_VAE model at epoch 17\n",
      "Epoch 18, Training Loss: 143.60328467814128, Validation Loss: 143.5943125\n",
      "Saving Standard_VAE model at epoch 18\n",
      "Epoch 19, Training Loss: 143.4516175333659, Validation Loss: 143.41570349121093\n",
      "Saving Standard_VAE model at epoch 19\n",
      "Epoch 20, Training Loss: 143.21687490844727, Validation Loss: 143.85960611979166\n",
      "Saving Standard_VAE model at epoch 20\n",
      "Epoch 21, Training Loss: 143.08890220133463, Validation Loss: 143.33858968098957\n",
      "Saving Standard_VAE model at epoch 21\n",
      "Epoch 22, Training Loss: 142.8947004292806, Validation Loss: 143.1347384033203\n",
      "Saving Standard_VAE model at epoch 22\n",
      "Epoch 23, Training Loss: 142.81225947062174, Validation Loss: 143.0719365641276\n",
      "Saving Standard_VAE model at epoch 23\n",
      "Epoch 24, Training Loss: 142.6405101623535, Validation Loss: 142.98959318033855\n",
      "Saving Standard_VAE model at epoch 24\n",
      "Epoch 25, Training Loss: 142.43042376708985, Validation Loss: 142.4888771565755\n",
      "Saving Standard_VAE model at epoch 25\n",
      "Epoch 26, Training Loss: 142.3765920715332, Validation Loss: 142.53969506835938\n",
      "Saving Standard_VAE model at epoch 26\n",
      "Epoch 27, Training Loss: 142.26457732137044, Validation Loss: 142.72898099772135\n",
      "Saving Standard_VAE model at epoch 27\n",
      "Epoch 28, Training Loss: 142.1260087890625, Validation Loss: 142.5352001139323\n",
      "Saving Standard_VAE model at epoch 28\n",
      "Epoch 29, Training Loss: 142.01371103922526, Validation Loss: 142.27250211588543\n",
      "Saving Standard_VAE model at epoch 29\n",
      "Epoch 30, Training Loss: 141.87936100260416, Validation Loss: 143.14438521321614\n",
      "Saving Standard_VAE model at epoch 30\n",
      "Epoch 31, Training Loss: 141.7935635477702, Validation Loss: 142.00678035481772\n",
      "Saving Standard_VAE model at epoch 31\n",
      "Epoch 32, Training Loss: 141.70210382080077, Validation Loss: 142.1311727294922\n",
      "Saving Standard_VAE model at epoch 32\n",
      "Epoch 33, Training Loss: 141.56378250122071, Validation Loss: 141.84126981608074\n",
      "Saving Standard_VAE model at epoch 33\n",
      "Epoch 34, Training Loss: 141.51330684407552, Validation Loss: 142.02204069010418\n",
      "Saving Standard_VAE model at epoch 34\n",
      "Epoch 35, Training Loss: 141.40367259724934, Validation Loss: 142.05803662109375\n",
      "Saving Standard_VAE model at epoch 35\n",
      "Epoch 36, Training Loss: 141.38570097859701, Validation Loss: 142.03259065755208\n",
      "Saving Standard_VAE model at epoch 36\n",
      "Epoch 37, Training Loss: 141.31929832967123, Validation Loss: 141.44660677083334\n",
      "Saving Standard_VAE model at epoch 37\n",
      "Epoch 38, Training Loss: 141.1710627746582, Validation Loss: 141.85800333658855\n",
      "Saving Standard_VAE model at epoch 38\n",
      "Epoch 39, Training Loss: 141.09024997965494, Validation Loss: 141.72654720052083\n",
      "Saving Standard_VAE model at epoch 39\n",
      "Epoch 40, Training Loss: 141.05914420572915, Validation Loss: 141.64492659505208\n",
      "Saving Standard_VAE model at epoch 40\n",
      "Epoch 41, Training Loss: 140.98817630004882, Validation Loss: 141.39395845540363\n",
      "Saving Standard_VAE model at epoch 41\n",
      "Epoch 42, Training Loss: 140.8950601908366, Validation Loss: 141.642072265625\n",
      "Saving Standard_VAE model at epoch 42\n",
      "Epoch 43, Training Loss: 140.85156979370117, Validation Loss: 141.38947080485025\n",
      "Saving Standard_VAE model at epoch 43\n",
      "Epoch 44, Training Loss: 140.77714032999674, Validation Loss: 141.2740308227539\n",
      "Saving Standard_VAE model at epoch 44\n",
      "Epoch 45, Training Loss: 140.74389707438152, Validation Loss: 141.41803771972656\n",
      "Saving Standard_VAE model at epoch 45\n",
      "Epoch 46, Training Loss: 140.742868174235, Validation Loss: 141.34620540364583\n",
      "Saving Standard_VAE model at epoch 46\n",
      "Epoch 47, Training Loss: 140.629009765625, Validation Loss: 141.22336828613282\n",
      "Saving Standard_VAE model at epoch 47\n",
      "Epoch 48, Training Loss: 140.5193780415853, Validation Loss: 141.44897440592447\n",
      "Saving Standard_VAE model at epoch 48\n",
      "Epoch 49, Training Loss: 140.5726382751465, Validation Loss: 141.1663400065104\n",
      "Saving Standard_VAE model at epoch 49\n",
      "Epoch 50, Training Loss: 140.50475013224283, Validation Loss: 141.2429520670573\n",
      "Saving Standard_VAE model at epoch 50\n",
      "Epoch 51, Training Loss: 140.44694613647462, Validation Loss: 141.33976942952475\n",
      "Saving Standard_VAE model at epoch 51\n",
      "Epoch 52, Training Loss: 140.39110639444988, Validation Loss: 141.30677502441407\n",
      "Saving Standard_VAE model at epoch 52\n",
      "Epoch 53, Training Loss: 140.4129146830241, Validation Loss: 141.05342207845052\n",
      "Saving Standard_VAE model at epoch 53\n",
      "Epoch 54, Training Loss: 140.2980838317871, Validation Loss: 141.39018920898437\n",
      "Saving Standard_VAE model at epoch 54\n",
      "Epoch 55, Training Loss: 140.28655143229167, Validation Loss: 140.95414904785156\n",
      "Saving Standard_VAE model at epoch 55\n",
      "Epoch 56, Training Loss: 140.23628491210937, Validation Loss: 141.1806669108073\n",
      "Saving Standard_VAE model at epoch 56\n",
      "Epoch 57, Training Loss: 140.15238367716472, Validation Loss: 140.9608330078125\n",
      "Saving Standard_VAE model at epoch 57\n",
      "Epoch 58, Training Loss: 140.16039962768554, Validation Loss: 141.04223803710937\n",
      "Saving Standard_VAE model at epoch 58\n",
      "Epoch 59, Training Loss: 140.16305553181965, Validation Loss: 140.8783068033854\n",
      "Saving Standard_VAE model at epoch 59\n",
      "Epoch 60, Training Loss: 140.0872542622884, Validation Loss: 141.08316357421876\n",
      "Saving Standard_VAE model at epoch 60\n",
      "Epoch 61, Training Loss: 140.00442739868163, Validation Loss: 140.6137568766276\n",
      "Saving Standard_VAE model at epoch 61\n",
      "Epoch 62, Training Loss: 139.99377029418946, Validation Loss: 140.86481433105467\n",
      "Saving Standard_VAE model at epoch 62\n",
      "Epoch 63, Training Loss: 139.91291159057616, Validation Loss: 140.81532086181642\n",
      "Saving Standard_VAE model at epoch 63\n",
      "Epoch 64, Training Loss: 140.0299731648763, Validation Loss: 140.64814115397135\n",
      "Saving Standard_VAE model at epoch 64\n",
      "Epoch 65, Training Loss: 139.88603527832032, Validation Loss: 140.66734838867188\n",
      "Saving Standard_VAE model at epoch 65\n",
      "Epoch 66, Training Loss: 139.8605878499349, Validation Loss: 140.72782141113282\n",
      "Saving Standard_VAE model at epoch 66\n",
      "Epoch 67, Training Loss: 139.8887628580729, Validation Loss: 141.34559696451822\n",
      "Saving Standard_VAE model at epoch 67\n",
      "Epoch 68, Training Loss: 139.79447119140625, Validation Loss: 140.45711002604168\n",
      "Saving Standard_VAE model at epoch 68\n",
      "Epoch 69, Training Loss: 139.77541681925456, Validation Loss: 140.91709452311198\n",
      "Saving Standard_VAE model at epoch 69\n",
      "Epoch 70, Training Loss: 139.74829557291667, Validation Loss: 140.81833028157553\n",
      "Saving Standard_VAE model at epoch 70\n",
      "Epoch 71, Training Loss: 139.62113720703124, Validation Loss: 140.6098178507487\n",
      "Saving Standard_VAE model at epoch 71\n",
      "Epoch 72, Training Loss: 139.6467039388021, Validation Loss: 140.6467041015625\n",
      "Saving Standard_VAE model at epoch 72\n",
      "Epoch 73, Training Loss: 139.6590551961263, Validation Loss: 140.6544158528646\n",
      "Saving Standard_VAE model at epoch 73\n",
      "Epoch 74, Training Loss: 139.62071563720704, Validation Loss: 140.83990498860678\n",
      "Saving Standard_VAE model at epoch 74\n",
      "Epoch 75, Training Loss: 139.59443404134115, Validation Loss: 140.51224007161457\n",
      "Saving Standard_VAE model at epoch 75\n",
      "Epoch 76, Training Loss: 139.65339282226563, Validation Loss: 140.38598974609374\n",
      "Saving Standard_VAE model at epoch 76\n",
      "Epoch 77, Training Loss: 139.56819474283853, Validation Loss: 140.58655611165364\n",
      "Saving Standard_VAE model at epoch 77\n",
      "Epoch 78, Training Loss: 139.46963622029622, Validation Loss: 140.47880224609375\n",
      "Saving Standard_VAE model at epoch 78\n",
      "Epoch 79, Training Loss: 139.5672725423177, Validation Loss: 140.36858186848957\n",
      "Saving Standard_VAE model at epoch 79\n",
      "Epoch 80, Training Loss: 139.50310333251954, Validation Loss: 140.3447705078125\n",
      "Saving Standard_VAE model at epoch 80\n",
      "Epoch 81, Training Loss: 139.47019380696614, Validation Loss: 140.75619091796875\n",
      "Saving Standard_VAE model at epoch 81\n",
      "Epoch 82, Training Loss: 139.42715738932293, Validation Loss: 140.39897725423177\n",
      "Saving Standard_VAE model at epoch 82\n",
      "Epoch 83, Training Loss: 139.38307299804688, Validation Loss: 140.46226896158853\n",
      "Saving Standard_VAE model at epoch 83\n",
      "Epoch 84, Training Loss: 139.39982590738933, Validation Loss: 140.24136555989583\n",
      "Saving Standard_VAE model at epoch 84\n",
      "Epoch 85, Training Loss: 139.3480228169759, Validation Loss: 140.51393208821614\n",
      "Saving Standard_VAE model at epoch 85\n",
      "Epoch 86, Training Loss: 139.33690544637045, Validation Loss: 140.70102555338542\n",
      "Saving Standard_VAE model at epoch 86\n",
      "Epoch 87, Training Loss: 139.26724291992187, Validation Loss: 140.2456992594401\n",
      "Saving Standard_VAE model at epoch 87\n",
      "Epoch 88, Training Loss: 139.31519220987957, Validation Loss: 140.26477270507812\n",
      "Saving Standard_VAE model at epoch 88\n",
      "Epoch 89, Training Loss: 139.28284119669595, Validation Loss: 140.34184627278646\n",
      "Saving Standard_VAE model at epoch 89\n",
      "Epoch 90, Training Loss: 139.30222022501627, Validation Loss: 140.3629649251302\n",
      "Saving Standard_VAE model at epoch 90\n",
      "Epoch 91, Training Loss: 139.26619290161133, Validation Loss: 140.28466101074218\n",
      "Saving Standard_VAE model at epoch 91\n",
      "Epoch 92, Training Loss: 139.19088702392577, Validation Loss: 140.55844661458335\n",
      "Saving Standard_VAE model at epoch 92\n",
      "Epoch 93, Training Loss: 139.18988412475585, Validation Loss: 140.22236592610676\n",
      "Saving Standard_VAE model at epoch 93\n",
      "Epoch 94, Training Loss: 139.0993693745931, Validation Loss: 140.33123278808594\n",
      "Saving Standard_VAE model at epoch 94\n",
      "Epoch 95, Training Loss: 139.1266178487142, Validation Loss: 140.67712536621093\n",
      "Saving Standard_VAE model at epoch 95\n",
      "Epoch 96, Training Loss: 139.15871262613933, Validation Loss: 140.04709350585938\n",
      "Saving Standard_VAE model at epoch 96\n",
      "Epoch 97, Training Loss: 139.11373706054687, Validation Loss: 140.34888732910156\n",
      "Saving Standard_VAE model at epoch 97\n",
      "Epoch 98, Training Loss: 139.11943611653646, Validation Loss: 140.6206338704427\n",
      "Saving Standard_VAE model at epoch 98\n",
      "Epoch 99, Training Loss: 139.13502682495118, Validation Loss: 140.16271952311197\n",
      "Saving Standard_VAE model at epoch 99\n",
      "Epoch 100, Training Loss: 139.0287915140788, Validation Loss: 140.20280310058592\n",
      "Saving Standard_VAE model at epoch 100\n",
      "Best Standard_VAE model saved as best_Standard_VAE_epoch_95.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359db89af25b427c80e815c6dd5b37dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Training Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '17792019-aada-497a-81a2-337584bef66c',\n",
       "              'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                    19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "                    35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "                    51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "                    67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82,\n",
       "                    83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,\n",
       "                    99, 100],\n",
       "              'y': [216.63298744710286, 174.41765334065755, 159.54346567789713,\n",
       "                    154.21702128092448, 151.63424127197266, 150.0141619466146,\n",
       "                    148.69508521525066, 147.77145233154297, 146.95817606608074,\n",
       "                    146.36571536254883, 145.80335098266602, 145.41788624064128,\n",
       "                    144.99512973022462, 144.68754249064128, 144.37958308919272,\n",
       "                    144.07845701090494, 143.86202871704103, 143.60328467814128,\n",
       "                    143.4516175333659, 143.21687490844727, 143.08890220133463,\n",
       "                    142.8947004292806, 142.81225947062174, 142.6405101623535,\n",
       "                    142.43042376708985, 142.3765920715332, 142.26457732137044,\n",
       "                    142.1260087890625, 142.01371103922526, 141.87936100260416,\n",
       "                    141.7935635477702, 141.70210382080077, 141.56378250122071,\n",
       "                    141.51330684407552, 141.40367259724934, 141.38570097859701,\n",
       "                    141.31929832967123, 141.1710627746582, 141.09024997965494,\n",
       "                    141.05914420572915, 140.98817630004882, 140.8950601908366,\n",
       "                    140.85156979370117, 140.77714032999674, 140.74389707438152,\n",
       "                    140.742868174235, 140.629009765625, 140.5193780415853,\n",
       "                    140.5726382751465, 140.50475013224283, 140.44694613647462,\n",
       "                    140.39110639444988, 140.4129146830241, 140.2980838317871,\n",
       "                    140.28655143229167, 140.23628491210937, 140.15238367716472,\n",
       "                    140.16039962768554, 140.16305553181965, 140.0872542622884,\n",
       "                    140.00442739868163, 139.99377029418946, 139.91291159057616,\n",
       "                    140.0299731648763, 139.88603527832032, 139.8605878499349,\n",
       "                    139.8887628580729, 139.79447119140625, 139.77541681925456,\n",
       "                    139.74829557291667, 139.62113720703124, 139.6467039388021,\n",
       "                    139.6590551961263, 139.62071563720704, 139.59443404134115,\n",
       "                    139.65339282226563, 139.56819474283853, 139.46963622029622,\n",
       "                    139.5672725423177, 139.50310333251954, 139.47019380696614,\n",
       "                    139.42715738932293, 139.38307299804688, 139.39982590738933,\n",
       "                    139.3480228169759, 139.33690544637045, 139.26724291992187,\n",
       "                    139.31519220987957, 139.28284119669595, 139.30222022501627,\n",
       "                    139.26619290161133, 139.19088702392577, 139.18988412475585,\n",
       "                    139.0993693745931, 139.1266178487142, 139.15871262613933,\n",
       "                    139.11373706054687, 139.11943611653646, 139.13502682495118,\n",
       "                    139.0287915140788]},\n",
       "             {'mode': 'lines+markers',\n",
       "              'name': 'Validation Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f9c78698-6e4a-4596-b563-aa7ffdde5590',\n",
       "              'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                    19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "                    35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "                    51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "                    67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82,\n",
       "                    83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,\n",
       "                    99, 100],\n",
       "              'y': [186.9185244954427, 163.65676192220053, 156.08525419108074,\n",
       "                    152.24092138671875, 150.68963724772135, 148.87698071289063,\n",
       "                    148.07883365885417, 147.31320817057292, 146.63166748046876,\n",
       "                    146.11750146484374, 145.85103658040364, 145.6014795328776,\n",
       "                    144.71542622884115, 144.6293016357422, 144.34554337565103,\n",
       "                    143.9824989827474, 144.19640897623697, 143.5943125,\n",
       "                    143.41570349121093, 143.85960611979166, 143.33858968098957,\n",
       "                    143.1347384033203, 143.0719365641276, 142.98959318033855,\n",
       "                    142.4888771565755, 142.53969506835938, 142.72898099772135,\n",
       "                    142.5352001139323, 142.27250211588543, 143.14438521321614,\n",
       "                    142.00678035481772, 142.1311727294922, 141.84126981608074,\n",
       "                    142.02204069010418, 142.05803662109375, 142.03259065755208,\n",
       "                    141.44660677083334, 141.85800333658855, 141.72654720052083,\n",
       "                    141.64492659505208, 141.39395845540363, 141.642072265625,\n",
       "                    141.38947080485025, 141.2740308227539, 141.41803771972656,\n",
       "                    141.34620540364583, 141.22336828613282, 141.44897440592447,\n",
       "                    141.1663400065104, 141.2429520670573, 141.33976942952475,\n",
       "                    141.30677502441407, 141.05342207845052, 141.39018920898437,\n",
       "                    140.95414904785156, 141.1806669108073, 140.9608330078125,\n",
       "                    141.04223803710937, 140.8783068033854, 141.08316357421876,\n",
       "                    140.6137568766276, 140.86481433105467, 140.81532086181642,\n",
       "                    140.64814115397135, 140.66734838867188, 140.72782141113282,\n",
       "                    141.34559696451822, 140.45711002604168, 140.91709452311198,\n",
       "                    140.81833028157553, 140.6098178507487, 140.6467041015625,\n",
       "                    140.6544158528646, 140.83990498860678, 140.51224007161457,\n",
       "                    140.38598974609374, 140.58655611165364, 140.47880224609375,\n",
       "                    140.36858186848957, 140.3447705078125, 140.75619091796875,\n",
       "                    140.39897725423177, 140.46226896158853, 140.24136555989583,\n",
       "                    140.51393208821614, 140.70102555338542, 140.2456992594401,\n",
       "                    140.26477270507812, 140.34184627278646, 140.3629649251302,\n",
       "                    140.28466101074218, 140.55844661458335, 140.22236592610676,\n",
       "                    140.33123278808594, 140.67712536621093, 140.04709350585938,\n",
       "                    140.34888732910156, 140.6206338704427, 140.16271952311197,\n",
       "                    140.20280310058592]}],\n",
       "    'layout': {'height': 600,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Interactive Standard_VAE Training and Validation Loss'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run cell to train Standard VAE\n",
    "print(f'Training parameters: batch_size={batch_size}, learning_rate={learning_rate}, epochs={epochs}')\n",
    "print(\"Training Standard_VAE...\")\n",
    "Optimiser_Standard = torch.optim.Adam(Standard_VAE.parameters(), lr=learning_rate)\n",
    "Trained_Standard_VAE = train_vae(Standard_VAE, trainloader, validationloader, loss_function_standard, Optimiser_Standard, epochs, DEVICE, \"Standard_VAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters: batch_size=64, learning_rate=0.001, epochs=100\n",
      "Training Lake_VAE...\n",
      "Epoch 1, Training Loss: 196.0902937825521, Validation Loss: 154.23970231119793\n",
      "Saving Lake_VAE model at epoch 1\n",
      "Epoch 2, Training Loss: 146.30639093017578, Validation Loss: 139.89667443847657\n",
      "Saving Lake_VAE model at epoch 2\n",
      "Epoch 3, Training Loss: 136.34115384928384, Validation Loss: 132.61003776041667\n",
      "Saving Lake_VAE model at epoch 3\n",
      "Epoch 4, Training Loss: 130.5356474609375, Validation Loss: 128.2311095377604\n",
      "Saving Lake_VAE model at epoch 4\n",
      "Epoch 5, Training Loss: 127.09249858601888, Validation Loss: 125.73383709716796\n",
      "Saving Lake_VAE model at epoch 5\n",
      "Epoch 6, Training Loss: 125.20727039591472, Validation Loss: 124.09460024007161\n",
      "Saving Lake_VAE model at epoch 6\n",
      "Epoch 7, Training Loss: 123.87977361043295, Validation Loss: 123.33071480305989\n",
      "Saving Lake_VAE model at epoch 7\n",
      "Epoch 8, Training Loss: 122.89019830322266, Validation Loss: 122.39476843261718\n",
      "Saving Lake_VAE model at epoch 8\n",
      "Epoch 9, Training Loss: 122.05293002319335, Validation Loss: 121.8154501953125\n",
      "Saving Lake_VAE model at epoch 9\n",
      "Epoch 10, Training Loss: 121.40767249552408, Validation Loss: 120.94943668619791\n",
      "Saving Lake_VAE model at epoch 10\n",
      "Epoch 11, Training Loss: 120.81415353393555, Validation Loss: 120.4957021484375\n",
      "Saving Lake_VAE model at epoch 11\n",
      "Epoch 12, Training Loss: 120.31422602335611, Validation Loss: 120.44827600097656\n",
      "Saving Lake_VAE model at epoch 12\n",
      "Epoch 13, Training Loss: 119.86533670043946, Validation Loss: 119.60119657389323\n",
      "Saving Lake_VAE model at epoch 13\n",
      "Epoch 14, Training Loss: 119.44534773763021, Validation Loss: 119.844197652181\n",
      "Saving Lake_VAE model at epoch 14\n",
      "Epoch 15, Training Loss: 119.12221516927083, Validation Loss: 119.23626826985677\n",
      "Saving Lake_VAE model at epoch 15\n",
      "Epoch 16, Training Loss: 118.7988819885254, Validation Loss: 118.73732997639974\n",
      "Saving Lake_VAE model at epoch 16\n",
      "Epoch 17, Training Loss: 118.47555301920573, Validation Loss: 118.34342873128256\n",
      "Saving Lake_VAE model at epoch 17\n",
      "Epoch 18, Training Loss: 118.23139833577474, Validation Loss: 118.5932095743815\n",
      "Saving Lake_VAE model at epoch 18\n",
      "Epoch 19, Training Loss: 118.00347185262044, Validation Loss: 117.92502459716796\n",
      "Saving Lake_VAE model at epoch 19\n",
      "Epoch 20, Training Loss: 117.77246921793619, Validation Loss: 117.98064326985677\n",
      "Saving Lake_VAE model at epoch 20\n",
      "Epoch 21, Training Loss: 117.55478985595703, Validation Loss: 117.50523455810547\n",
      "Saving Lake_VAE model at epoch 21\n",
      "Epoch 22, Training Loss: 117.42700680541992, Validation Loss: 117.54378603108724\n",
      "Saving Lake_VAE model at epoch 22\n",
      "Epoch 23, Training Loss: 117.20087562052409, Validation Loss: 117.43766367594401\n",
      "Saving Lake_VAE model at epoch 23\n",
      "Epoch 24, Training Loss: 117.07351987711588, Validation Loss: 117.07759079996745\n",
      "Saving Lake_VAE model at epoch 24\n",
      "Epoch 25, Training Loss: 116.90007327270507, Validation Loss: 117.04484810384115\n",
      "Saving Lake_VAE model at epoch 25\n",
      "Epoch 26, Training Loss: 116.76599980672201, Validation Loss: 117.15965313720703\n",
      "Saving Lake_VAE model at epoch 26\n",
      "Epoch 27, Training Loss: 116.62910802205404, Validation Loss: 116.92300889078776\n",
      "Saving Lake_VAE model at epoch 27\n",
      "Epoch 28, Training Loss: 116.54760503133139, Validation Loss: 116.83664982096354\n",
      "Saving Lake_VAE model at epoch 28\n",
      "Epoch 29, Training Loss: 116.40948177083334, Validation Loss: 116.66415403238932\n",
      "Saving Lake_VAE model at epoch 29\n",
      "Epoch 30, Training Loss: 116.31768418375651, Validation Loss: 116.63568202718099\n",
      "Saving Lake_VAE model at epoch 30\n",
      "Epoch 31, Training Loss: 116.22654620361328, Validation Loss: 116.60967342122396\n",
      "Saving Lake_VAE model at epoch 31\n",
      "Epoch 32, Training Loss: 116.06128231811523, Validation Loss: 116.31492755126953\n",
      "Saving Lake_VAE model at epoch 32\n",
      "Epoch 33, Training Loss: 115.99330932617187, Validation Loss: 116.71696402994792\n",
      "Saving Lake_VAE model at epoch 33\n",
      "Epoch 34, Training Loss: 115.89798233032226, Validation Loss: 116.36523232014974\n",
      "Saving Lake_VAE model at epoch 34\n",
      "Epoch 35, Training Loss: 115.82593837483724, Validation Loss: 116.18949814860026\n",
      "Saving Lake_VAE model at epoch 35\n",
      "Epoch 36, Training Loss: 115.7122601216634, Validation Loss: 116.28447637939453\n",
      "Saving Lake_VAE model at epoch 36\n",
      "Epoch 37, Training Loss: 115.63428317260743, Validation Loss: 115.98764290364583\n",
      "Saving Lake_VAE model at epoch 37\n",
      "Epoch 38, Training Loss: 115.57552477010091, Validation Loss: 115.66441426595053\n",
      "Saving Lake_VAE model at epoch 38\n",
      "Epoch 39, Training Loss: 115.48648190307617, Validation Loss: 115.93767639160156\n",
      "Saving Lake_VAE model at epoch 39\n",
      "Epoch 40, Training Loss: 115.37809946695964, Validation Loss: 116.00771830240886\n",
      "Saving Lake_VAE model at epoch 40\n",
      "Epoch 41, Training Loss: 115.34693670654296, Validation Loss: 115.815708984375\n",
      "Saving Lake_VAE model at epoch 41\n",
      "Epoch 42, Training Loss: 115.29476695760091, Validation Loss: 115.66290209960937\n",
      "Saving Lake_VAE model at epoch 42\n",
      "Epoch 43, Training Loss: 115.25973521931967, Validation Loss: 115.54597703043619\n",
      "Saving Lake_VAE model at epoch 43\n",
      "Epoch 44, Training Loss: 115.1165530904134, Validation Loss: 115.60818650309245\n",
      "Saving Lake_VAE model at epoch 44\n",
      "Epoch 45, Training Loss: 115.0843555094401, Validation Loss: 115.62141463216146\n",
      "Saving Lake_VAE model at epoch 45\n",
      "Epoch 46, Training Loss: 115.06133051554362, Validation Loss: 115.59403529866536\n",
      "Saving Lake_VAE model at epoch 46\n",
      "Epoch 47, Training Loss: 114.99713818359375, Validation Loss: 115.48680912272135\n",
      "Saving Lake_VAE model at epoch 47\n",
      "Epoch 48, Training Loss: 114.98242888387044, Validation Loss: 115.17685036214193\n",
      "Saving Lake_VAE model at epoch 48\n",
      "Epoch 49, Training Loss: 114.87026114908853, Validation Loss: 115.1611128540039\n",
      "Saving Lake_VAE model at epoch 49\n",
      "Epoch 50, Training Loss: 114.82018392944336, Validation Loss: 115.4199262898763\n",
      "Saving Lake_VAE model at epoch 50\n",
      "Epoch 51, Training Loss: 114.81991946411132, Validation Loss: 115.37687731933593\n",
      "Saving Lake_VAE model at epoch 51\n",
      "Epoch 52, Training Loss: 114.78623080444336, Validation Loss: 115.21054233805339\n",
      "Saving Lake_VAE model at epoch 52\n",
      "Epoch 53, Training Loss: 114.7180575764974, Validation Loss: 115.2911610921224\n",
      "Saving Lake_VAE model at epoch 53\n",
      "Epoch 54, Training Loss: 114.70388145955404, Validation Loss: 115.36498177083334\n",
      "Saving Lake_VAE model at epoch 54\n",
      "Epoch 55, Training Loss: 114.67477773030599, Validation Loss: 115.10629132080078\n",
      "Saving Lake_VAE model at epoch 55\n",
      "Epoch 56, Training Loss: 114.6012618001302, Validation Loss: 115.05089404296875\n",
      "Saving Lake_VAE model at epoch 56\n",
      "Epoch 57, Training Loss: 114.59502209472656, Validation Loss: 114.92732586669922\n",
      "Saving Lake_VAE model at epoch 57\n",
      "Epoch 58, Training Loss: 114.53877364095052, Validation Loss: 115.05219911702474\n",
      "Saving Lake_VAE model at epoch 58\n",
      "Epoch 59, Training Loss: 114.48458589680989, Validation Loss: 115.02492696126302\n",
      "Saving Lake_VAE model at epoch 59\n",
      "Epoch 60, Training Loss: 114.42574167887369, Validation Loss: 115.0563739827474\n",
      "Saving Lake_VAE model at epoch 60\n",
      "Epoch 61, Training Loss: 114.44451311238606, Validation Loss: 115.13149739583334\n",
      "Saving Lake_VAE model at epoch 61\n",
      "Epoch 62, Training Loss: 114.33991088867188, Validation Loss: 114.81391813151042\n",
      "Saving Lake_VAE model at epoch 62\n",
      "Epoch 63, Training Loss: 114.34041815185547, Validation Loss: 114.86876892089843\n",
      "Saving Lake_VAE model at epoch 63\n",
      "Epoch 64, Training Loss: 114.32465512084961, Validation Loss: 114.88148752848308\n",
      "Saving Lake_VAE model at epoch 64\n",
      "Epoch 65, Training Loss: 114.28066196695964, Validation Loss: 115.20142860921224\n",
      "Saving Lake_VAE model at epoch 65\n",
      "Epoch 66, Training Loss: 114.24060566202799, Validation Loss: 114.74357456461588\n",
      "Saving Lake_VAE model at epoch 66\n",
      "Epoch 67, Training Loss: 114.26659387207032, Validation Loss: 114.92439786783854\n",
      "Saving Lake_VAE model at epoch 67\n",
      "Epoch 68, Training Loss: 114.21314726765951, Validation Loss: 114.59261118570963\n",
      "Saving Lake_VAE model at epoch 68\n",
      "Epoch 69, Training Loss: 114.15380487060547, Validation Loss: 114.73839208984376\n",
      "Saving Lake_VAE model at epoch 69\n",
      "Epoch 70, Training Loss: 114.1181530863444, Validation Loss: 114.83511853027343\n",
      "Saving Lake_VAE model at epoch 70\n",
      "Epoch 71, Training Loss: 114.16579455566406, Validation Loss: 114.70969527180989\n",
      "Saving Lake_VAE model at epoch 71\n",
      "Epoch 72, Training Loss: 114.05283123779297, Validation Loss: 114.60546958414713\n",
      "Saving Lake_VAE model at epoch 72\n",
      "Epoch 73, Training Loss: 114.08615184529623, Validation Loss: 114.84549668375651\n",
      "Saving Lake_VAE model at epoch 73\n",
      "Epoch 74, Training Loss: 113.99907804361979, Validation Loss: 114.7212382405599\n",
      "Saving Lake_VAE model at epoch 74\n",
      "Epoch 75, Training Loss: 114.00660569254558, Validation Loss: 114.73550754801433\n",
      "Saving Lake_VAE model at epoch 75\n",
      "Epoch 76, Training Loss: 113.96733004760742, Validation Loss: 114.5040121866862\n",
      "Saving Lake_VAE model at epoch 76\n",
      "Epoch 77, Training Loss: 113.93074170939127, Validation Loss: 114.71977262369792\n",
      "Saving Lake_VAE model at epoch 77\n",
      "Epoch 78, Training Loss: 113.92415395100912, Validation Loss: 114.56534545898438\n",
      "Saving Lake_VAE model at epoch 78\n",
      "Epoch 79, Training Loss: 113.90283278401692, Validation Loss: 114.63288321940104\n",
      "Saving Lake_VAE model at epoch 79\n",
      "Epoch 80, Training Loss: 113.88480310058594, Validation Loss: 114.83417372639974\n",
      "Saving Lake_VAE model at epoch 80\n",
      "Epoch 81, Training Loss: 113.88304682413737, Validation Loss: 114.45609604899089\n",
      "Saving Lake_VAE model at epoch 81\n",
      "Epoch 82, Training Loss: 113.82294235229492, Validation Loss: 114.60535115559895\n",
      "Saving Lake_VAE model at epoch 82\n",
      "Epoch 83, Training Loss: 113.82253939819336, Validation Loss: 114.5985527750651\n",
      "Saving Lake_VAE model at epoch 83\n",
      "Epoch 84, Training Loss: 113.80569682820638, Validation Loss: 114.499582417806\n",
      "Saving Lake_VAE model at epoch 84\n",
      "Epoch 85, Training Loss: 113.75216943359375, Validation Loss: 114.48798378499349\n",
      "Saving Lake_VAE model at epoch 85\n",
      "Epoch 86, Training Loss: 113.76933590698242, Validation Loss: 114.28919356282552\n",
      "Saving Lake_VAE model at epoch 86\n",
      "Epoch 87, Training Loss: 113.70836751302083, Validation Loss: 114.33686409505208\n",
      "Saving Lake_VAE model at epoch 87\n",
      "Epoch 88, Training Loss: 113.7375835571289, Validation Loss: 114.47677880859375\n",
      "Saving Lake_VAE model at epoch 88\n",
      "Epoch 89, Training Loss: 113.7354406636556, Validation Loss: 114.48634301757812\n",
      "Saving Lake_VAE model at epoch 89\n",
      "Epoch 90, Training Loss: 113.67655150349935, Validation Loss: 114.3674326171875\n",
      "Saving Lake_VAE model at epoch 90\n",
      "Epoch 91, Training Loss: 113.67893559773763, Validation Loss: 114.69456077067058\n",
      "Saving Lake_VAE model at epoch 91\n",
      "Epoch 92, Training Loss: 113.64637936401367, Validation Loss: 114.24787282307943\n",
      "Saving Lake_VAE model at epoch 92\n",
      "Epoch 93, Training Loss: 113.61927223714193, Validation Loss: 114.21324051920573\n",
      "Saving Lake_VAE model at epoch 93\n",
      "Epoch 94, Training Loss: 113.59661889648437, Validation Loss: 114.31283902994792\n",
      "Saving Lake_VAE model at epoch 94\n",
      "Epoch 95, Training Loss: 113.57860787963867, Validation Loss: 114.58629923502605\n",
      "Saving Lake_VAE model at epoch 95\n",
      "Epoch 96, Training Loss: 113.59575701904296, Validation Loss: 114.28547766113282\n",
      "Saving Lake_VAE model at epoch 96\n",
      "Epoch 97, Training Loss: 113.54884864298502, Validation Loss: 114.31640791829427\n",
      "Saving Lake_VAE model at epoch 97\n",
      "Epoch 98, Training Loss: 113.5693368326823, Validation Loss: 114.2045220336914\n",
      "Saving Lake_VAE model at epoch 98\n",
      "Epoch 99, Training Loss: 113.54481460571289, Validation Loss: 114.37663928222656\n",
      "Saving Lake_VAE model at epoch 99\n",
      "Epoch 100, Training Loss: 113.52057537841797, Validation Loss: 114.25029868570964\n",
      "Saving Lake_VAE model at epoch 100\n",
      "Best Lake_VAE model saved as best_Lake_VAE_epoch_97.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38186f92baa4f63ae54d4cb288138ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Training Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e4a5419b-30b1-4557-b6df-28d6caf173cb',\n",
       "              'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                    19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "                    35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "                    51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "                    67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82,\n",
       "                    83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,\n",
       "                    99, 100],\n",
       "              'y': [196.0902937825521, 146.30639093017578, 136.34115384928384,\n",
       "                    130.5356474609375, 127.09249858601888, 125.20727039591472,\n",
       "                    123.87977361043295, 122.89019830322266, 122.05293002319335,\n",
       "                    121.40767249552408, 120.81415353393555, 120.31422602335611,\n",
       "                    119.86533670043946, 119.44534773763021, 119.12221516927083,\n",
       "                    118.7988819885254, 118.47555301920573, 118.23139833577474,\n",
       "                    118.00347185262044, 117.77246921793619, 117.55478985595703,\n",
       "                    117.42700680541992, 117.20087562052409, 117.07351987711588,\n",
       "                    116.90007327270507, 116.76599980672201, 116.62910802205404,\n",
       "                    116.54760503133139, 116.40948177083334, 116.31768418375651,\n",
       "                    116.22654620361328, 116.06128231811523, 115.99330932617187,\n",
       "                    115.89798233032226, 115.82593837483724, 115.7122601216634,\n",
       "                    115.63428317260743, 115.57552477010091, 115.48648190307617,\n",
       "                    115.37809946695964, 115.34693670654296, 115.29476695760091,\n",
       "                    115.25973521931967, 115.1165530904134, 115.0843555094401,\n",
       "                    115.06133051554362, 114.99713818359375, 114.98242888387044,\n",
       "                    114.87026114908853, 114.82018392944336, 114.81991946411132,\n",
       "                    114.78623080444336, 114.7180575764974, 114.70388145955404,\n",
       "                    114.67477773030599, 114.6012618001302, 114.59502209472656,\n",
       "                    114.53877364095052, 114.48458589680989, 114.42574167887369,\n",
       "                    114.44451311238606, 114.33991088867188, 114.34041815185547,\n",
       "                    114.32465512084961, 114.28066196695964, 114.24060566202799,\n",
       "                    114.26659387207032, 114.21314726765951, 114.15380487060547,\n",
       "                    114.1181530863444, 114.16579455566406, 114.05283123779297,\n",
       "                    114.08615184529623, 113.99907804361979, 114.00660569254558,\n",
       "                    113.96733004760742, 113.93074170939127, 113.92415395100912,\n",
       "                    113.90283278401692, 113.88480310058594, 113.88304682413737,\n",
       "                    113.82294235229492, 113.82253939819336, 113.80569682820638,\n",
       "                    113.75216943359375, 113.76933590698242, 113.70836751302083,\n",
       "                    113.7375835571289, 113.7354406636556, 113.67655150349935,\n",
       "                    113.67893559773763, 113.64637936401367, 113.61927223714193,\n",
       "                    113.59661889648437, 113.57860787963867, 113.59575701904296,\n",
       "                    113.54884864298502, 113.5693368326823, 113.54481460571289,\n",
       "                    113.52057537841797]},\n",
       "             {'mode': 'lines+markers',\n",
       "              'name': 'Validation Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '4ed3a5ce-ddd9-4aa4-a8a0-288070e8722f',\n",
       "              'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                    19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "                    35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "                    51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "                    67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82,\n",
       "                    83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,\n",
       "                    99, 100],\n",
       "              'y': [154.23970231119793, 139.89667443847657, 132.61003776041667,\n",
       "                    128.2311095377604, 125.73383709716796, 124.09460024007161,\n",
       "                    123.33071480305989, 122.39476843261718, 121.8154501953125,\n",
       "                    120.94943668619791, 120.4957021484375, 120.44827600097656,\n",
       "                    119.60119657389323, 119.844197652181, 119.23626826985677,\n",
       "                    118.73732997639974, 118.34342873128256, 118.5932095743815,\n",
       "                    117.92502459716796, 117.98064326985677, 117.50523455810547,\n",
       "                    117.54378603108724, 117.43766367594401, 117.07759079996745,\n",
       "                    117.04484810384115, 117.15965313720703, 116.92300889078776,\n",
       "                    116.83664982096354, 116.66415403238932, 116.63568202718099,\n",
       "                    116.60967342122396, 116.31492755126953, 116.71696402994792,\n",
       "                    116.36523232014974, 116.18949814860026, 116.28447637939453,\n",
       "                    115.98764290364583, 115.66441426595053, 115.93767639160156,\n",
       "                    116.00771830240886, 115.815708984375, 115.66290209960937,\n",
       "                    115.54597703043619, 115.60818650309245, 115.62141463216146,\n",
       "                    115.59403529866536, 115.48680912272135, 115.17685036214193,\n",
       "                    115.1611128540039, 115.4199262898763, 115.37687731933593,\n",
       "                    115.21054233805339, 115.2911610921224, 115.36498177083334,\n",
       "                    115.10629132080078, 115.05089404296875, 114.92732586669922,\n",
       "                    115.05219911702474, 115.02492696126302, 115.0563739827474,\n",
       "                    115.13149739583334, 114.81391813151042, 114.86876892089843,\n",
       "                    114.88148752848308, 115.20142860921224, 114.74357456461588,\n",
       "                    114.92439786783854, 114.59261118570963, 114.73839208984376,\n",
       "                    114.83511853027343, 114.70969527180989, 114.60546958414713,\n",
       "                    114.84549668375651, 114.7212382405599, 114.73550754801433,\n",
       "                    114.5040121866862, 114.71977262369792, 114.56534545898438,\n",
       "                    114.63288321940104, 114.83417372639974, 114.45609604899089,\n",
       "                    114.60535115559895, 114.5985527750651, 114.499582417806,\n",
       "                    114.48798378499349, 114.28919356282552, 114.33686409505208,\n",
       "                    114.47677880859375, 114.48634301757812, 114.3674326171875,\n",
       "                    114.69456077067058, 114.24787282307943, 114.21324051920573,\n",
       "                    114.31283902994792, 114.58629923502605, 114.28547766113282,\n",
       "                    114.31640791829427, 114.2045220336914, 114.37663928222656,\n",
       "                    114.25029868570964]}],\n",
       "    'layout': {'height': 600,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Interactive Lake_VAE Training and Validation Loss'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run cell to train Lake VAE\n",
    "print(f'Training parameters: batch_size={batch_size}, learning_rate={learning_rate}, epochs={epochs}')\n",
    "print(\"Training Lake_VAE...\")\n",
    "Optimiser_Lake = torch.optim.Adam(Lake_VAE.parameters(), lr=learning_rate)\n",
    "Trained_Lake_VAE = train_vae(Lake_VAE, trainloader, validationloader, loss_function_lake, Optimiser_Lake, epochs, DEVICE, \"Lake_VAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training only uses 25MiB of GPU memory. Perhaps could try Jupyterlab and jupyterlab-nvdashboard to monitor GPU usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_standard_vae_path = 'best_Standard_VAE_epoch_X.pth'\n",
    "# best_lake_vae_path = 'best_Lake_VAE_epoch_Y.pth'\n",
    "\n",
    "standard_vae_path = 'Standard_VAE_100.pth'\n",
    "lake_vae_path = 'Lake_VAE_100.pth'\n",
    "\n",
    "# Load the best models\n",
    "Standard_VAE = StandardVAE().to(DEVICE)\n",
    "load_model(Standard_VAE, standard_vae_path, DEVICE)\n",
    "\n",
    "Lake_VAE = LakeVAE().to(DEVICE)\n",
    "load_model(Lake_VAE, lake_vae_path, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Trained Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_processing = False\n",
    "\n",
    "def reconstruct_from_latent_space(model, latent_point, pca, device):\n",
    "    original_latent = pca.inverse_transform([latent_point])\n",
    "    original_latent_tensor = torch.from_numpy(original_latent).float().to(device)\n",
    "    reconstructed_img = model.decode(original_latent_tensor).cpu()\n",
    "    return reconstructed_img[0].squeeze()\n",
    "\n",
    "def plot_latent_space_interactive(model, data_loader, device, vaename, dataname, num_samples=1000):\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encode(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            if len(latents) * data_loader.batch_size > num_samples:\n",
    "                break\n",
    "\n",
    "    latents = np.concatenate(latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    latents_reduced = pca.fit_transform(latents)\n",
    "\n",
    "    # Define a custom color scale (10 different colors for digits 0-9)\n",
    "    custom_color_scale = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A',\n",
    "                          '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52']\n",
    "\n",
    "    # Create traces for each digit with hover text\n",
    "    traces = []\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(labels == digit)[0]\n",
    "        trace = go.Scatter(\n",
    "            x=latents_reduced[digit_indices, 0], y=latents_reduced[digit_indices, 1],\n",
    "            mode='markers', marker=dict(color=custom_color_scale[digit], size=10),\n",
    "            name=str(digit),\n",
    "            hoverinfo='text',\n",
    "            text=[f'Label: {digit}, Pos: ({x:.2f}, {y:.2f})' for x, y in latents_reduced[digit_indices]]\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    # Plotly figure with separate traces\n",
    "    fig = go.FigureWidget(traces)\n",
    "    fig.update_layout(\n",
    "        title=f'{vaename} Latent Space Visualisation of MNIST {dataname} Data',\n",
    "        xaxis_title='Principal Component 1',\n",
    "        yaxis_title='Principal Component 2',\n",
    "        width=800, height=600,\n",
    "        legend_title_text='Digit Label'\n",
    "    )\n",
    "\n",
    "    def update_image(trace, points, selector):\n",
    "        global is_processing\n",
    "        if is_processing:\n",
    "            return\n",
    "    \n",
    "        is_processing = True\n",
    "    \n",
    "        if points.point_inds:\n",
    "            idx = points.point_inds[0]\n",
    "            latent_point = latents_reduced[idx]\n",
    "            img = reconstruct_from_latent_space(model, latent_point, pca, device)\n",
    "            plt.imshow(img.detach().numpy(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            display(plt.gcf())\n",
    "    \n",
    "        is_processing = False\n",
    "\n",
    "    for trace in fig.data:\n",
    "        trace.on_click(update_image)\n",
    "\n",
    "    display(fig)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61829268e604980b3abe3b80f9f00c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'text',\n",
       "              'marker': {'color': '#636EFA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '0',\n",
       "              'text': [Label: 0, Pos: (1.82, 1.63), Label: 0, Pos: (1.18, 0.33),\n",
       "                       Label: 0, Pos: (1.95, 0.46), ..., Label: 0, Pos: (0.87,\n",
       "                       0.74), Label: 0, Pos: (1.77, 0.79), Label: 0, Pos: (1.73,\n",
       "                       1.23)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '8f3218e9-6974-4a1d-8508-c5b31a00d15a',\n",
       "              'x': array([1.8172448, 1.1837072, 1.948814 , ..., 0.8692725, 1.7679049, 1.7311076],\n",
       "                         dtype=float32),\n",
       "              'y': array([1.6332574 , 0.33297515, 0.46378666, ..., 0.7351385 , 0.7881625 ,\n",
       "                          1.2339143 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#EF553B', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '1',\n",
       "              'text': [Label: 1, Pos: (0.05, -1.34), Label: 1, Pos: (-1.30,\n",
       "                       -1.56), Label: 1, Pos: (-0.07, -2.00), ..., Label: 1, Pos:\n",
       "                       (-0.95, -1.37), Label: 1, Pos: (-0.18, -2.12), Label: 1,\n",
       "                       Pos: (-0.52, -1.66)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a249b5a4-c806-41e9-a924-2def677a85da',\n",
       "              'x': array([ 0.05166232, -1.2986089 , -0.06571646, ..., -0.9504941 , -0.18084311,\n",
       "                          -0.5203289 ], dtype=float32),\n",
       "              'y': array([-1.3366177, -1.5585215, -1.9990826, ..., -1.373095 , -2.12195  ,\n",
       "                          -1.6638304], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#00CC96', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '2',\n",
       "              'text': [Label: 2, Pos: (1.07, -0.67), Label: 2, Pos: (1.99, -0.07),\n",
       "                       Label: 2, Pos: (1.22, -0.91), ..., Label: 2, Pos: (1.05,\n",
       "                       -0.49), Label: 2, Pos: (0.71, -0.65), Label: 2, Pos: (1.64,\n",
       "                       -0.90)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ee14c953-e4a6-46e8-92ac-f414d39363fe',\n",
       "              'x': array([1.0683663 , 1.9887713 , 1.2237817 , ..., 1.0547886 , 0.70670617,\n",
       "                          1.6410661 ], dtype=float32),\n",
       "              'y': array([-0.6730273 , -0.07382592, -0.91410035, ..., -0.4912602 , -0.6525968 ,\n",
       "                          -0.8953484 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#AB63FA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '3',\n",
       "              'text': [Label: 3, Pos: (0.04, -0.06), Label: 3, Pos: (-0.01,\n",
       "                       -0.35), Label: 3, Pos: (0.58, 0.21), ..., Label: 3, Pos:\n",
       "                       (0.66, -0.06), Label: 3, Pos: (0.02, -0.45), Label: 3, Pos:\n",
       "                       (0.90, -0.19)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '70003491-44db-4af9-892d-196c7f389e2e',\n",
       "              'x': array([ 0.04132968, -0.00721595,  0.5821965 , ...,  0.66063935,  0.02049435,\n",
       "                           0.8985862 ], dtype=float32),\n",
       "              'y': array([-0.06404412, -0.34668425,  0.21050933, ..., -0.05558202, -0.44936332,\n",
       "                          -0.18940897], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FFA15A', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '4',\n",
       "              'text': [Label: 4, Pos: (-1.15, 3.04), Label: 4, Pos: (-1.39, 1.54),\n",
       "                       Label: 4, Pos: (-0.36, 0.29), ..., Label: 4, Pos: (-1.16,\n",
       "                       0.94), Label: 4, Pos: (-0.92, -0.27), Label: 4, Pos: (-1.18,\n",
       "                       0.14)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '33912467-4517-4881-977b-96864612940f',\n",
       "              'x': array([-1.1459525 , -1.3854177 , -0.3644438 , ..., -1.1570991 , -0.92406106,\n",
       "                          -1.17925   ], dtype=float32),\n",
       "              'y': array([ 3.041343  ,  1.538227  ,  0.28784436, ...,  0.94079876, -0.27171284,\n",
       "                           0.14343576], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#19D3F3', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '5',\n",
       "              'text': [Label: 5, Pos: (0.14, 0.05), Label: 5, Pos: (0.55, -0.11),\n",
       "                       Label: 5, Pos: (0.70, 0.44), ..., Label: 5, Pos: (0.06,\n",
       "                       0.61), Label: 5, Pos: (0.11, 0.17), Label: 5, Pos: (0.59,\n",
       "                       0.05)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '63c501a5-99fe-4509-aa32-add336e0e6cb',\n",
       "              'x': array([0.13738073, 0.5534871 , 0.69820035, ..., 0.06161771, 0.10935154,\n",
       "                          0.5873661 ], dtype=float32),\n",
       "              'y': array([ 0.05311374, -0.1118248 ,  0.43520817, ...,  0.60928226,  0.16907252,\n",
       "                           0.05279003], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF6692', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '6',\n",
       "              'text': [Label: 6, Pos: (0.48, 0.24), Label: 6, Pos: (1.05, 0.61),\n",
       "                       Label: 6, Pos: (0.62, 0.53), ..., Label: 6, Pos: (0.91,\n",
       "                       0.99), Label: 6, Pos: (0.98, 1.52), Label: 6, Pos: (0.85,\n",
       "                       0.13)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '35a4e61b-1730-465b-a2aa-cbaa2704145f',\n",
       "              'x': array([0.48495784, 1.0497962 , 0.62294924, ..., 0.913967  , 0.9764295 ,\n",
       "                          0.8533131 ], dtype=float32),\n",
       "              'y': array([0.23577936, 0.6083692 , 0.52502835, ..., 0.9909203 , 1.5236449 ,\n",
       "                          0.12582363], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#B6E880', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '7',\n",
       "              'text': [Label: 7, Pos: (-1.04, -0.08), Label: 7, Pos: (-1.14,\n",
       "                       1.51), Label: 7, Pos: (-2.15, -0.02), ..., Label: 7, Pos:\n",
       "                       (-1.63, -0.29), Label: 7, Pos: (-0.64, -0.47), Label: 7,\n",
       "                       Pos: (-2.12, -0.35)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '1cd22ef7-b443-4161-ab71-bb7b4fb4ba17',\n",
       "              'x': array([-1.0406808, -1.1445351, -2.1506345, ..., -1.6256832, -0.6422119,\n",
       "                          -2.1202757], dtype=float32),\n",
       "              'y': array([-0.07874829,  1.5121726 , -0.02161862, ..., -0.29469573, -0.47397757,\n",
       "                          -0.35267586], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF97FF', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '8',\n",
       "              'text': [Label: 8, Pos: (-0.10, -0.01), Label: 8, Pos: (-1.60,\n",
       "                       0.13), Label: 8, Pos: (0.33, -0.34), ..., Label: 8, Pos:\n",
       "                       (0.47, -0.38), Label: 8, Pos: (0.28, -0.39), Label: 8, Pos:\n",
       "                       (0.01, -0.28)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '698d56e6-5847-4bcd-8717-5badef6f0035',\n",
       "              'x': array([-0.09531224, -1.603146  ,  0.32574597, ...,  0.4666246 ,  0.28234565,\n",
       "                           0.00889554], dtype=float32),\n",
       "              'y': array([-0.01161774,  0.12634072, -0.33641863, ..., -0.3823862 , -0.389814  ,\n",
       "                          -0.27520508], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FECB52', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '9',\n",
       "              'text': [Label: 9, Pos: (-1.17, 0.92), Label: 9, Pos: (-0.04,\n",
       "                       -0.33), Label: 9, Pos: (-0.72, 0.72), ..., Label: 9, Pos:\n",
       "                       (-0.95, -0.40), Label: 9, Pos: (-1.10, 0.27), Label: 9, Pos:\n",
       "                       (-0.84, 0.09)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '155f67b8-bb9c-4640-8213-3fc3a3e3075c',\n",
       "              'x': array([-1.1727438 , -0.04162555, -0.7218368 , ..., -0.9477287 , -1.0963098 ,\n",
       "                          -0.84044915], dtype=float32),\n",
       "              'y': array([ 0.9163426 , -0.32808802,  0.72092605, ..., -0.39802057,  0.26658192,\n",
       "                           0.09043997], dtype=float32)}],\n",
       "    'layout': {'height': 600,\n",
       "               'legend': {'title': {'text': 'Digit Label'}},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Standard VAE Epochs Latent Space Visualisation of MNIST Validation Data'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'title': {'text': 'Principal Component 1'}},\n",
       "               'yaxis': {'title': {'text': 'Principal Component 2'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_latent_space_interactive(Standard_VAE, trainloader, DEVICE, 'Standard VAE Epochs' ,'Training', num_samples=500)\n",
    "plot_latent_space_interactive(Standard_VAE, validationloader, DEVICE, 'Standard VAE Epochs' ,'Validation', num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b189a3ea41b4aef9d3a960daf96c4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'text',\n",
       "              'marker': {'color': '#636EFA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '0',\n",
       "              'text': [Label: 0, Pos: (0.75, 1.43), Label: 0, Pos: (1.41, 0.85),\n",
       "                       Label: 0, Pos: (0.65, 2.25), ..., Label: 0, Pos: (0.77,\n",
       "                       1.70), Label: 0, Pos: (0.68, 1.31), Label: 0, Pos: (0.78,\n",
       "                       2.26)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '828907ff-30d6-44cf-a2e2-a7ea0b6830d8',\n",
       "              'x': array([0.7487708 , 1.41007   , 0.65171856, ..., 0.76621723, 0.6832378 ,\n",
       "                          0.77587986], dtype=float32),\n",
       "              'y': array([1.427808  , 0.84818727, 2.2479963 , ..., 1.6952932 , 1.3135802 ,\n",
       "                          2.2552798 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#EF553B', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '1',\n",
       "              'text': [Label: 1, Pos: (0.91, -0.69), Label: 1, Pos: (1.15, -0.43),\n",
       "                       Label: 1, Pos: (0.46, -0.86), ..., Label: 1, Pos: (0.01,\n",
       "                       -1.08), Label: 1, Pos: (0.21, -0.63), Label: 1, Pos: (0.65,\n",
       "                       -0.68)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dd08ddde-8e07-4ee5-ac21-4d7934c8dcf0',\n",
       "              'x': array([0.9070993 , 1.1516689 , 0.45670667, ..., 0.00912313, 0.20751114,\n",
       "                          0.64658344], dtype=float32),\n",
       "              'y': array([-0.68976754, -0.43241543, -0.8572554 , ..., -1.0763967 , -0.6348815 ,\n",
       "                          -0.67614686], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#00CC96', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '2',\n",
       "              'text': [Label: 2, Pos: (-0.94, -0.25), Label: 2, Pos: (-0.47,\n",
       "                       -0.52), Label: 2, Pos: (-0.47, -0.48), ..., Label: 2, Pos:\n",
       "                       (0.96, 0.53), Label: 2, Pos: (0.84, -0.64), Label: 2, Pos:\n",
       "                       (-0.18, -1.03)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '9a07bbb4-486f-40d6-b4b1-b989be6620aa',\n",
       "              'x': array([-0.9422383 , -0.46828824, -0.47037488, ...,  0.95993066,  0.8379113 ,\n",
       "                          -0.18198274], dtype=float32),\n",
       "              'y': array([-0.24663782, -0.5196577 , -0.47908866, ...,  0.52890724, -0.6397945 ,\n",
       "                          -1.0286517 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#AB63FA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '3',\n",
       "              'text': [Label: 3, Pos: (1.45, -0.10), Label: 3, Pos: (0.39, 0.23),\n",
       "                       Label: 3, Pos: (0.01, -1.23), ..., Label: 3, Pos: (0.82,\n",
       "                       0.72), Label: 3, Pos: (1.03, -0.45), Label: 3, Pos: (0.98,\n",
       "                       -0.22)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e4fe312d-f184-4b83-8f12-56a1f92befd4',\n",
       "              'x': array([1.4547625 , 0.39291164, 0.01456858, ..., 0.8219205 , 1.0307118 ,\n",
       "                          0.98293847], dtype=float32),\n",
       "              'y': array([-0.09990022,  0.23497581, -1.2293969 , ...,  0.7197344 , -0.44644144,\n",
       "                          -0.2202192 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FFA15A', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '4',\n",
       "              'text': [Label: 4, Pos: (-0.91, -0.16), Label: 4, Pos: (0.62, 0.17),\n",
       "                       Label: 4, Pos: (-0.51, -0.12), ..., Label: 4, Pos: (0.40,\n",
       "                       -1.00), Label: 4, Pos: (-0.76, 0.33), Label: 4, Pos: (-0.47,\n",
       "                       0.22)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '541e2104-4c0b-4abf-aa5b-80842aff58ad',\n",
       "              'x': array([-0.9135429 ,  0.6214678 , -0.5072046 , ...,  0.39525104, -0.76086146,\n",
       "                          -0.46925193], dtype=float32),\n",
       "              'y': array([-0.16185464,  0.17163695, -0.11540218, ..., -1.0015664 ,  0.33106074,\n",
       "                           0.22359142], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#19D3F3', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '5',\n",
       "              'text': [Label: 5, Pos: (0.35, -1.25), Label: 5, Pos: (-0.12,\n",
       "                       -0.94), Label: 5, Pos: (-1.57, -0.48), ..., Label: 5, Pos:\n",
       "                       (-0.72, -1.29), Label: 5, Pos: (0.22, -0.47), Label: 5, Pos:\n",
       "                       (-0.59, -1.65)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c2c20411-e4d6-4169-b98c-7a5f335456eb',\n",
       "              'x': array([ 0.3501501 , -0.11714172, -1.5727386 , ..., -0.72045517,  0.21685621,\n",
       "                          -0.585798  ], dtype=float32),\n",
       "              'y': array([-1.2458766 , -0.9362389 , -0.47805184, ..., -1.2855564 , -0.4678187 ,\n",
       "                          -1.64713   ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF6692', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '6',\n",
       "              'text': [Label: 6, Pos: (0.17, 0.67), Label: 6, Pos: (0.73, 0.83),\n",
       "                       Label: 6, Pos: (-0.40, 1.73), ..., Label: 6, Pos: (0.63,\n",
       "                       -0.35), Label: 6, Pos: (1.29, -0.98), Label: 6, Pos: (0.44,\n",
       "                       1.36)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b5c28fe6-6213-4d7c-a4b4-f3086f1c1125',\n",
       "              'x': array([ 0.17031878,  0.7326011 , -0.40141866, ...,  0.6250893 ,  1.2851286 ,\n",
       "                           0.43741062], dtype=float32),\n",
       "              'y': array([ 0.67075306,  0.83361065,  1.7349168 , ..., -0.34895068, -0.9820941 ,\n",
       "                           1.359684  ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#B6E880', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '7',\n",
       "              'text': [Label: 7, Pos: (-1.70, -0.69), Label: 7, Pos: (-1.55,\n",
       "                       0.47), Label: 7, Pos: (-1.42, 0.36), ..., Label: 7, Pos:\n",
       "                       (0.26, -0.23), Label: 7, Pos: (-0.61, 0.59), Label: 7, Pos:\n",
       "                       (-1.29, -0.11)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '7cc97023-7530-4968-96ed-bc97992c67f1',\n",
       "              'x': array([-1.7043834 , -1.5487533 , -1.4234712 , ...,  0.26437294, -0.6120799 ,\n",
       "                          -1.2910161 ], dtype=float32),\n",
       "              'y': array([-0.6927377 ,  0.47408313,  0.36348167, ..., -0.22909616,  0.59034884,\n",
       "                          -0.10964558], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF97FF', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '8',\n",
       "              'text': [Label: 8, Pos: (0.26, -0.36), Label: 8, Pos: (-0.54,\n",
       "                       -0.03), Label: 8, Pos: (1.03, -0.47), ..., Label: 8, Pos:\n",
       "                       (1.20, 0.38), Label: 8, Pos: (-0.18, -0.70), Label: 8, Pos:\n",
       "                       (0.17, -0.57)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '6a8d5b38-dbaf-4e22-842d-aba339259e77',\n",
       "              'x': array([ 0.25670645, -0.5426515 ,  1.0270241 , ...,  1.1952666 , -0.17591205,\n",
       "                           0.16696018], dtype=float32),\n",
       "              'y': array([-0.36141244, -0.03261384, -0.4719636 , ...,  0.37531716, -0.6977457 ,\n",
       "                          -0.57463986], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FECB52', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '9',\n",
       "              'text': [Label: 9, Pos: (-0.33, -0.24), Label: 9, Pos: (-0.22,\n",
       "                       -0.35), Label: 9, Pos: (-0.06, 0.06), ..., Label: 9, Pos:\n",
       "                       (-1.09, 0.17), Label: 9, Pos: (-0.95, 0.15), Label: 9, Pos:\n",
       "                       (-1.01, -0.74)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fa024e42-7126-4acf-a6c5-da5e4ac45fc3',\n",
       "              'x': array([-0.32856598, -0.22061425, -0.0550377 , ..., -1.0944456 , -0.95241815,\n",
       "                          -1.0120634 ], dtype=float32),\n",
       "              'y': array([-0.24363704, -0.34825522,  0.05502873, ...,  0.16653177,  0.14532831,\n",
       "                          -0.73934597], dtype=float32)}],\n",
       "    'layout': {'height': 600,\n",
       "               'legend': {'title': {'text': 'Digit Label'}},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'layer-constrained VAE Epochs Latent Space Visualisation of MNIST Validiation Data'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'title': {'text': 'Principal Component 1'}},\n",
       "               'yaxis': {'title': {'text': 'Principal Component 2'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_latent_space_interactive(Lake_VAE, trainloader, DEVICE, 'layer-constrained VAE Epochs', 'Training', num_samples=500)\n",
    "plot_latent_space_interactive(Lake_VAE, validationloader, DEVICE, 'layer-constrained VAE Epochs', 'Validiation', num_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Density Estimation Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 900 MNIST validation images (labelled 0) and 100 GAN generated MNIST images (labelled 1) to create a combined testing dataset. \n",
    "Then attempting to see if the LAKE anomaly detection can find the synthetic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of pixel values: 0.0 to 1.0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the validation dataset\n",
    "mnist_validation_data = validation_dataset \n",
    "\n",
    "# Extract MNIST images and labels\n",
    "mnist_images = mnist_validation_data.dataset.data[mnist_validation_data.indices][:900]\n",
    "mnist_labels = torch.zeros(900)  # Label '0' for real MNIST data\n",
    "\n",
    "# Load GAN generated images\n",
    "gan_images_path = 'gan_generated_mnist_images.pt'\n",
    "gan_images = torch.load(gan_images_path)\n",
    "\n",
    "# Normalize the MNIST and GAN images if they are not already\n",
    "mnist_images = mnist_images.float() / 255.0\n",
    "mnist_images = mnist_images[:,None]\n",
    "gan_images = gan_images.float() / 255.0 if gan_images.max() > 1.0 else gan_images\n",
    "\n",
    "# Add a pure white image as an anomaly\n",
    "white_image = torch.ones(1, 1, 28, 28)\n",
    "white_label = torch.tensor([1])  # Anomaly label\n",
    "\n",
    "# Combine MNIST, GAN, and white image into one dataset\n",
    "combined_images = torch.cat((mnist_images, gan_images, white_image), dim=0)\n",
    "combined_labels = torch.cat((mnist_labels, torch.ones(100), white_label), dim=0)\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "combined_dataset = TensorDataset(combined_images, combined_labels)\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Check the normalization\n",
    "max_pixel_value = combined_images.max()\n",
    "min_pixel_value = combined_images.min()\n",
    "print(f\"Range of pixel values: {min_pixel_value} to {max_pixel_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 12)\n",
      "(1001, 12)\n"
     ]
    }
   ],
   "source": [
    "# Function to encode dataset and compute reconstruction errors\n",
    "def encode_and_reconstruct(model, dataloader, device):\n",
    "    model.eval()\n",
    "    ws = []\n",
    "    rec_errors = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            # Get w and x' in forward pass\n",
    "            recon_x, _, _, _, _, _, w, _, _, _ = model(x)\n",
    "\n",
    "            # Store w\n",
    "            ws.append(w.cpu()) \n",
    "\n",
    "            # Calc and store rec_eu and rec_co\n",
    "            rec_euclidean = torch.norm(x - recon_x, p=2, dim=(1, 2, 3))\n",
    "            rec_cosine = F.cosine_similarity(x.view(x.size(0), -1), recon_x.view(recon_x.size(0), -1), dim=1)\n",
    "            r = torch.stack((rec_euclidean, rec_cosine), dim=1)\n",
    "            rec_errors.append(r.cpu()) \n",
    "            \n",
    "    return torch.cat(ws, dim=0), torch.cat(rec_errors, dim=0)\n",
    "    \n",
    "Lake_VAE.to(DEVICE)\n",
    "\n",
    "# For Training Data\n",
    "encoded_ws, reconstruction_rs = encode_and_reconstruct(Lake_VAE, trainloader, DEVICE)\n",
    "assert not torch.isnan(encoded_ws).any(), \"NaNs in encoded_ws\"\n",
    "assert not torch.isnan(reconstruction_rs).any(), \"NaNs in reconstruction_rs\"\n",
    "C_Train = np.hstack((encoded_ws, reconstruction_rs))\n",
    "print(C_Train.shape)\n",
    "\n",
    "# Testing Data\n",
    "encoded_ws, reconstruction_rs = encode_and_reconstruct(Lake_VAE, combined_loader, DEVICE)\n",
    "assert not torch.isnan(encoded_ws).any(), \"NaNs in encoded_ws\"\n",
    "assert not torch.isnan(reconstruction_rs).any(), \"NaNs in reconstruction_rs\"\n",
    "C = np.hstack((encoded_ws, reconstruction_rs))\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main things that affect the anomaly detection results. <br>\n",
    "A. The model used (how well the data is compressed). The ability of your VAE to compress and reconstruct data is critical. It is contained within w and r. <br>\n",
    "B. The KDE's bandwidth setting, corresponding to the smoothness of the density estimate. <br>\n",
    "If it's too narrow, you might have a very bumpy estimate that's sensitive to noise. <br>\n",
    "If it's too wide, the estimate might be too smooth and anomalies could be missed because they blend in with the normal data. <br>\n",
    "C. Anomaly detection threshold. What proportion of your dataset you set expected to be an anomaly. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KernelDensity from sklearn represents fh(s) = (1/n) ∑[i=1 to n] Kh(s - ci)\n",
    "from joblib import dump\n",
    "\n",
    "def perform_kde(C_Train):\n",
    "    # Doing k-fold validation on to find good bandwidth value\n",
    "    params = {'bandwidth': np.linspace(0.01, 0.2, 20)}\n",
    "    grid = GridSearchCV(KernelDensity(kernel='gaussian'), params, cv=5)\n",
    "    grid.fit(C_Train)\n",
    "    print(f\"Optimal bandwidth: {grid.best_estimator_.bandwidth}\")\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=grid.best_estimator_.bandwidth)\n",
    "    \n",
    "    #kde = KernelDensity(kernel='gaussian', bandwidth=0.05) # Manual bandwidth setting\n",
    "    kde.fit(C_Train)\n",
    "    return kde\n",
    "\n",
    "# Function to estimate density from C values\n",
    "def estimate_density(kde, C):\n",
    "    log_density = kde.score_samples(C)\n",
    "    return np.exp(log_density)\n",
    "\n",
    "# Calibrate and Save KDE\n",
    "kde_model = perform_kde(C_Train)\n",
    "dump(kde_model, 'kde_model.joblib')\n",
    "\n",
    "density_estimates = estimate_density(kde_model, C)\n",
    "\n",
    "# Determine anomaly threshold and detect anomalies\n",
    "threshold = np.percentile(density_estimates, 10)\n",
    "anomalies = density_estimates < threshold\n",
    "\n",
    "# Calculate and print anomaly detection results\n",
    "detected_anomalies = np.sum(anomalies[-101:]) \n",
    "print(f\"Detected {detected_anomalies} anomalies out of 101 synthetic images.\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(density_estimates, bins=100, alpha=0.5, color='blue', label='Density Scores')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.title('Density Estimates and Anomaly Threshold')\n",
    "plt.xlabel('Density Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 10 anomalies out of 101 synthetic images.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calibrate and Save KDE\n",
    "from joblib import load\n",
    "kde_model = load('kde_model.joblib')\n",
    "\n",
    "# Function to estimate density from C values\n",
    "def estimate_density(kde, C):\n",
    "    log_density = kde.score_samples(C)\n",
    "    return np.exp(log_density)\n",
    "\n",
    "density_estimates = estimate_density(kde_model, C)\n",
    "\n",
    "# Determine anomaly threshold and detect anomalies\n",
    "threshold = np.percentile(density_estimates, 10)\n",
    "anomalies = density_estimates < threshold\n",
    "\n",
    "# Calculate and print anomaly detection results\n",
    "detected_anomalies = np.sum(anomalies[-101:]) \n",
    "print(f\"Detected {detected_anomalies} anomalies out of 101 synthetic images.\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(density_estimates, bins=100, alpha=0.5, color='blue', label='Density Scores')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.title('Density Estimates and Anomaly Threshold')\n",
    "plt.xlabel('Density Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objs as go\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GPU acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the GPU acceleration properly up on Pytorch for a .ipynb file on Axon. <br>\n",
    "You have to first use nvidia-smi to see an unused GPU,  <br>\n",
    "then use nvidia-smi -L to see its MIG ID, and set it as an environmental variable.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for the CUDA_VISIBLE_DEVICES value\n",
    "cuda_device = input(\"Enter the CUDA_VISIBLE_DEVICES value: \")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cuda_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(\"Is CUDA available:\", is_cuda_available)\n",
    "\n",
    "# Determine the device to use: GPU (CUDA), Apple Silicon (MPS), or CPU\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tensor on CUDA: tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Test tensor operation on GPU\n",
    "    test_tensor = torch.tensor([1.0, 2.0, 3.0], device=\"cuda\")\n",
    "    print(\"Test tensor on CUDA:\", test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully moved a tensor to the device: tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if is_cuda_available:\n",
    "    try:\n",
    "        test_tensor = torch.tensor([1, 2, 3], device=DEVICE)\n",
    "        print(\"Successfully moved a tensor to the device:\", test_tensor)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error moving a tensor to the device:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining VAE classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20, w_dim=10):\n",
    "        super(StandardVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder layers\n",
    "        # Input: [bs, 1, 28, 28]\n",
    "        self.enc_conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)  # Output: [bs, 16, 14, 14]\n",
    "        self.enc_conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1) # Output: [bs, 32, 7, 7]\n",
    "        self.enc_fc1 = nn.Linear(32 * 7 * 7, w_dim)  # Output: [bs, 128]\n",
    "        # Two output layers for the latent space\n",
    "        self.enc_fc2 = nn.Linear(w_dim, latent_dim)  # For mu, Output: [bs, latent_dim]\n",
    "        self.enc_fc3 = nn.Linear(w_dim, latent_dim)  # For logvar, Output: [bs, latent_dim]\n",
    "\n",
    "        # Decoder layers\n",
    "        self.dec_fc1 = nn.Linear(latent_dim, w_dim)  # Output: [bs, 128]\n",
    "        self.dec_fc2 = nn.Linear(w_dim, 32 * 7 * 7)  # Output: [bs, 1568]\n",
    "        self.dec_conv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: [bs, 16, 14, 14]\n",
    "        self.dec_conv2 = nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: [bs, 1, 28, 28]\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.enc_conv1(x))\n",
    "        h = F.relu(self.enc_conv2(h))\n",
    "        h = torch.flatten(h, start_dim=1)\n",
    "        h = F.relu(self.enc_fc1(h))\n",
    "        return self.enc_fc2(h), self.enc_fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        # Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.dec_fc1(z)) \n",
    "        h = F.relu(self.dec_fc2(h)).view(-1, 32, 7, 7) # .view reshapes [bs, 1568] to [bs, 32, 7, 7]\n",
    "        h = F.relu(self.dec_conv1(h))\n",
    "        return torch.sigmoid(self.dec_conv2(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), z, mu, logvar\n",
    "\n",
    "def loss_function_standard(recon_x, z, mu, logvar, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Can reweight BCE + KLD as desired\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LakeVAE inheirits from StandardVAE, but with a modified forward pass.\n",
    "Its encoding and decoding layers are identicle. \n",
    "The only difference is that the forward pass stores and returns all the intermediate values required to calculate the modified reconstruction loss.\n",
    "\n",
    "Since pixel values are either 0 or 1, we can use BCE between the input image and output image.\n",
    "However, for the intermediate layers, that are continuous, we use can MSE instead. This is also what the paper's code does in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LakeVAE(StandardVAE):\n",
    "    def forward(self, x):\n",
    "        # Encoder layers\n",
    "        # Input: [bs, 1, 28, 28]\n",
    "        enc_conv1_out = F.relu(self.enc_conv1(x))  # Output: [bs, 16, 14, 14]\n",
    "        enc_conv2_out = F.relu(self.enc_conv2(enc_conv1_out))  # Output: [bs, 32, 7, 7]\n",
    "        flattened = torch.flatten(enc_conv2_out, start_dim=1)  # Output: [bs, 1568]\n",
    "        \n",
    "        w = F.relu(self.enc_fc1(flattened))  # Output: [bs, 128] # Eqn (5) in LAKE paper\n",
    "        # w = self.enc_fc1(flattened)  # Not sure if relu is used in the paper or not. Output: [bs, 128] # Eqn (5) in LAKE paper\n",
    "        \n",
    "        mu, logvar = self.enc_fc2(w), self.enc_fc3(w)  # Output: [bs, latent_dim], [bs, latent_dim] # Eqn (6) in LAKE paper\n",
    "\n",
    "        # Reparameterization and Decoding layers\n",
    "        z = self.reparameterize(mu, logvar)  # Output: [bs, latent_dim] # Eqn (7) in LAKE paper\n",
    "        dec_fc1_out = F.relu(self.dec_fc1(z))  # Output: [bs, 128]\n",
    "        dec_fc2_out = F.relu(self.dec_fc2(dec_fc1_out)).view(-1, 32, 7, 7)  # Output: [bs, 1568], then reshaped to [bs, 32, 7, 7]\n",
    "        dec_conv1_out = F.relu(self.dec_conv1(dec_fc2_out))  # Output: [bs, 16, 14, 14]\n",
    "        recon_x = torch.sigmoid(self.dec_conv2(dec_conv1_out))  # Output: [bs, 1, 28, 28]\n",
    "\n",
    "        return recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out\n",
    "\n",
    "def loss_function_lake(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # Layer-wise reconstruction loss\n",
    "    layer_loss = F.mse_loss(enc_conv1_out, dec_conv1_out) + F.mse_loss(enc_conv2_out, dec_fc2_out) + F.mse_loss(w, dec_fc1_out)\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD + layer_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_BCE(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    # Autoencoder\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    return BCE\n",
    "\n",
    "def loss_function_BCE_KLD(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    # Variational Autoencoder\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "def loss_function_KLD(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    # No reconstruction loss, just KLD\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_lake_BCEH(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # Layer-wise reconstruction loss\n",
    "    layer_loss = F.mse_loss(enc_conv1_out, dec_conv1_out) + F.mse_loss(enc_conv2_out, dec_fc2_out) + F.mse_loss(w, dec_fc1_out)\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return 1.5 * BCE + KLD + layer_loss\n",
    "\n",
    "def loss_function_lake_LLH(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # Layer-wise reconstruction loss\n",
    "    layer_loss = F.mse_loss(enc_conv1_out, dec_conv1_out) + F.mse_loss(enc_conv2_out, dec_fc2_out) + F.mse_loss(w, dec_fc1_out)\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD + 1.5 * layer_loss\n",
    "\n",
    "def loss_function_lake_KLDH(recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # Layer-wise reconstruction loss\n",
    "    layer_loss = F.mse_loss(enc_conv1_out, dec_conv1_out) + F.mse_loss(enc_conv2_out, dec_fc2_out) + F.mse_loss(w, dec_fc1_out)\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + 1.5 * KLD + layer_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definining Utility Classes for training and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, latent_vectors, folder=\"generated_images\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = model.decode(latent_vectors).cpu()\n",
    "    for i, img in enumerate(generated):\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "        plt.savefig(f\"{folder}/img_{epoch}_{i}.png\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, data_loader, device, num_samples=1000):\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encode(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            if len(latents) * data_loader.batch_size > num_samples:\n",
    "                break\n",
    "    \n",
    "    latents = np.concatenate(latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    latents_reduced = pca.fit_transform(latents)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(latents_reduced[:, 0], latents_reduced[:, 1], c=labels, cmap='viridis', s=2, alpha=0.6)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Latent Space (PCA-reduced)\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.show()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_processing = False\n",
    "def plot_losses_interactive(model, model_name, model_states, train_losses, val_losses, train_loader, val_loader, device, best_train_loss, best_val_loss):\n",
    "    global is_processing\n",
    "    epochs = len(train_losses)\n",
    "    fig = go.FigureWidget()\n",
    "\n",
    "    # Add traces for training and validation losses\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=train_losses, mode='lines+markers', name='Training Loss'))\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=val_losses, mode='lines+markers', name='Validation Loss'))\n",
    "\n",
    "    # Set layout for the plot\n",
    "    fig.update_layout(\n",
    "        title=f'Interactive {model_name} Training and Validation Loss',\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis_title='Loss',\n",
    "        width=800, height=600\n",
    "    )\n",
    "\n",
    "    # Function to update the image on clicking a point on the plot\n",
    "    def update_image(trace, points, selector):\n",
    "        global is_processing\n",
    "        if is_processing:\n",
    "            return\n",
    "        is_processing = True\n",
    "    \n",
    "        if points.point_inds:\n",
    "            epoch = points.point_inds[0]\n",
    "            model.load_state_dict(model_states[epoch])\n",
    "            model.eval()\n",
    "    \n",
    "            # Determine which dataloader and best loss to use based on which trace was clicked\n",
    "            if trace.name == 'Training Loss':\n",
    "                data_loader = train_loader\n",
    "                current_loss = train_losses[epoch]\n",
    "                best_loss = best_train_loss\n",
    "                loss_type = 'Training'\n",
    "            elif trace.name == 'Validation Loss':\n",
    "                data_loader = val_loader\n",
    "                current_loss = val_losses[epoch]\n",
    "                best_loss = best_val_loss\n",
    "                loss_type = 'Validation'\n",
    "\n",
    "            # Calculate loss as a percentage of the best loss\n",
    "            loss_percentage = (best_loss / current_loss) * 100\n",
    "\n",
    "            # Generate and display an image\n",
    "            data, _ = next(iter(data_loader))\n",
    "            data = data.to(device)\n",
    "            reconstructed_img = model(data)[0].cpu().squeeze()\n",
    "\n",
    "            if reconstructed_img.ndim == 3:  # If image has 3 dimensions, take the first one\n",
    "                reconstructed_img = reconstructed_img[0]\n",
    "\n",
    "            # Display information and the image\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(reconstructed_img.detach().numpy(), cmap='gray')\n",
    "            plt.title(f'{model_name} {loss_type} Loss\\nEpoch: {epoch + 1}\\nLoss: {current_loss:.4f} ({loss_percentage:.2f}% rel to best)')\n",
    "            plt.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            display(plt.gcf())\n",
    "            model.train()\n",
    "    \n",
    "        is_processing = False\n",
    "\n",
    "    # Attach the click handler to the plot\n",
    "    fig.data[0].on_click(update_image)  # For training loss\n",
    "    fig.data[1].on_click(update_image)  # For validation loss\n",
    "\n",
    "    # Display the plot\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_vae(model, val_loader, loss_function, device):\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = loss_function(*outputs, data)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify train_vae to instead to the probability density estimation training.\n",
    "I'm not sure how its training, or what this is doing, considering there's no updates to anything?\n",
    "write the functions for rec_euclidean and rec_cosine.\n",
    "The first thing the VAE classes return with their forward pass is their reconstructed images x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, val_loader, loss_function, optimiser, epochs, device, model_name, plot_interval=1):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model_states = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = loss_function(*outputs, data)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss = total_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = validate_vae(model, val_loader, loss_function, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Save the current model state\n",
    "        model_states.append(model.state_dict().copy())\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            best_epoch = epoch\n",
    "\n",
    "        print(f'Epoch {epoch}, Training Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "\n",
    "        #print(f'Saving {model_name} model at epoch {epoch+1}')\n",
    "        #save_model(model, f'{model_name}_{epoch+1}.pth')\n",
    "    \n",
    "    print(f'Saving {model_name} model at epoch {epoch}')\n",
    "    save_model(model, f'{model_name}_{epoch}.pth')\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model_path = f\"best_{model_name}_epoch_{best_epoch}.pth\"\n",
    "        save_model(model, model_path)\n",
    "        print(f\"Best {model_name} model saved as {model_path}\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    best_train_loss = min(train_losses)\n",
    "    best_val_loss = min(val_losses)\n",
    "    plot_losses_interactive(model, model_name, model_states, train_losses, val_losses, train_loader, val_loader, device, best_train_loss, best_val_loss)\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell loads in the mnist dataset into train, validation, and test dataloaders.\n",
    "While doing so, they are normalised to be [0,1] and turned into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Splitting the dataset into train and validation sets\n",
    "train_size = int(0.8 * len(mnist_trainset))\n",
    "validation_size = len(mnist_trainset) - train_size\n",
    "train_dataset, validation_dataset = random_split(mnist_trainset, [train_size, validation_size])\n",
    "\n",
    "# Download and load the test data\n",
    "test_dataset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training parameters for Lake_VAE: batch_size=64, learning_rate=0.001, epochs=20\n",
      "Training Lake_VAE...\n",
      "Epoch 0, Training Loss: 230.23481791178386, Validation Loss: 194.87613789876303\n",
      "Epoch 1, Training Loss: 186.2711146850586, Validation Loss: 178.6407814941406\n",
      "Epoch 2, Training Loss: 174.232154683431, Validation Loss: 171.26728019205729\n",
      "Epoch 3, Training Loss: 168.977066019694, Validation Loss: 168.24895430501303\n",
      "Epoch 4, Training Loss: 166.0485137532552, Validation Loss: 165.09962561035155\n",
      "Epoch 5, Training Loss: 163.81256709798177, Validation Loss: 163.46529447428387\n",
      "Epoch 6, Training Loss: 162.2378692220052, Validation Loss: 161.9512920735677\n",
      "Epoch 7, Training Loss: 161.0247784830729, Validation Loss: 161.90023787434896\n",
      "Epoch 8, Training Loss: 160.2353113606771, Validation Loss: 160.7356766764323\n",
      "Epoch 9, Training Loss: 159.58676143391926, Validation Loss: 159.8791602783203\n",
      "Epoch 10, Training Loss: 159.04939935302735, Validation Loss: 159.7861544596354\n",
      "Epoch 11, Training Loss: 158.73976971435548, Validation Loss: 159.79769384765626\n",
      "Epoch 12, Training Loss: 158.35760959879556, Validation Loss: 159.16059505208332\n",
      "Epoch 13, Training Loss: 158.00300805664062, Validation Loss: 158.71072249348958\n",
      "Epoch 14, Training Loss: 157.67387974039713, Validation Loss: 158.38251892089843\n",
      "Epoch 15, Training Loss: 157.3698304239909, Validation Loss: 158.61228987630207\n",
      "Epoch 16, Training Loss: 157.1857124226888, Validation Loss: 157.8021327311198\n",
      "Epoch 17, Training Loss: 156.89337622070312, Validation Loss: 158.49213688151042\n",
      "Epoch 18, Training Loss: 156.71688714599608, Validation Loss: 158.18903645833333\n",
      "Epoch 19, Training Loss: 156.52139398193358, Validation Loss: 157.42608268229168\n",
      "Saving Lake_VAE model at epoch 19\n",
      "Best Lake_VAE model saved as best_Lake_VAE_epoch_19.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ec86d941424dd2abe8e440245753bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Training Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd3013ac2-70fa-45d3-84cd-3e96a7f6a876',\n",
       "              'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                    19, 20],\n",
       "              'y': [230.23481791178386, 186.2711146850586, 174.232154683431,\n",
       "                    168.977066019694, 166.0485137532552, 163.81256709798177,\n",
       "                    162.2378692220052, 161.0247784830729, 160.2353113606771,\n",
       "                    159.58676143391926, 159.04939935302735, 158.73976971435548,\n",
       "                    158.35760959879556, 158.00300805664062, 157.67387974039713,\n",
       "                    157.3698304239909, 157.1857124226888, 156.89337622070312,\n",
       "                    156.71688714599608, 156.52139398193358]},\n",
       "             {'mode': 'lines+markers',\n",
       "              'name': 'Validation Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '0a96b012-42e8-4c33-8169-4a13b33e9702',\n",
       "              'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                    19, 20],\n",
       "              'y': [194.87613789876303, 178.6407814941406, 171.26728019205729,\n",
       "                    168.24895430501303, 165.09962561035155, 163.46529447428387,\n",
       "                    161.9512920735677, 161.90023787434896, 160.7356766764323,\n",
       "                    159.8791602783203, 159.7861544596354, 159.79769384765626,\n",
       "                    159.16059505208332, 158.71072249348958, 158.38251892089843,\n",
       "                    158.61228987630207, 157.8021327311198, 158.49213688151042,\n",
       "                    158.18903645833333, 157.42608268229168]}],\n",
       "    'layout': {'height': 600,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Interactive Lake_VAE Training and Validation Loss'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training parameters for BCE_VAE: batch_size=64, learning_rate=0.001, epochs=20\n",
      "Training BCE_VAE...\n",
      "Epoch 0, Training Loss: 214.68458685302735, Validation Loss: 178.6963399658203\n",
      "Epoch 1, Training Loss: 161.76713985188803, Validation Loss: 154.2126718343099\n",
      "Epoch 2, Training Loss: 149.75878578694662, Validation Loss: 147.65531892903647\n",
      "Epoch 3, Training Loss: 144.9340247192383, Validation Loss: 143.587231648763\n",
      "Epoch 4, Training Loss: 142.25095857747397, Validation Loss: 141.96136405436198\n",
      "Epoch 5, Training Loss: 140.46748248291016, Validation Loss: 140.55045735677083\n",
      "Epoch 6, Training Loss: 139.2454682413737, Validation Loss: 140.04225463867186\n",
      "Epoch 7, Training Loss: 138.3644733988444, Validation Loss: 138.51169718424478\n",
      "Epoch 8, Training Loss: 137.5494010925293, Validation Loss: 138.0346201171875\n",
      "Epoch 9, Training Loss: 136.94591638183593, Validation Loss: 137.4847499186198\n",
      "Epoch 10, Training Loss: 136.40975993855795, Validation Loss: 137.08745678710937\n",
      "Epoch 11, Training Loss: 135.96041111246745, Validation Loss: 136.54122587076822\n",
      "Epoch 12, Training Loss: 135.5126459859212, Validation Loss: 135.9950480957031\n",
      "Epoch 13, Training Loss: 135.1458648783366, Validation Loss: 135.87254626464843\n",
      "Epoch 14, Training Loss: 134.8012468363444, Validation Loss: 135.3976415201823\n",
      "Epoch 15, Training Loss: 134.5377011006673, Validation Loss: 135.00388468424478\n",
      "Epoch 16, Training Loss: 134.27285096232097, Validation Loss: 135.13233020019533\n"
     ]
    }
   ],
   "source": [
    "# Run cell to train all 7 models\n",
    "loss_functions = {\n",
    "    'loss_function_lake': 'Lake_VAE',\n",
    "    'loss_function_BCE': 'BCE_VAE',\n",
    "    'loss_function_BCE_KLD': 'BCE_KLD_VAE',\n",
    "    'loss_function_KLD': 'KLD_VAE',\n",
    "    'loss_function_lake_BCEH': 'lake_BCEH_VAE',\n",
    "    'loss_function_lake_LLH': 'lake_LLH_VAE',\n",
    "    'loss_function_lake_KLDH': 'lake_KLDH_VAE'\n",
    "}\n",
    "\n",
    "# Training each model with its respective loss function\n",
    "for loss_function_name, model_name in loss_functions.items():\n",
    "    # Create the model\n",
    "    model = LakeVAE().to(DEVICE)\n",
    "    print(f'\\nTraining parameters for {model_name}: batch_size={batch_size}, learning_rate={learning_rate}, epochs={epochs}')\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # Select the loss function dynamically\n",
    "    loss_function = globals()[loss_function_name]\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    trained_model = train_vae(model, trainloader, validationloader, loss_function, optimizer, epochs, DEVICE, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lake_VAE = LakeVAE().to(DEVICE)\n",
    "# Run cell to train Lake VAE\n",
    "print(f'Training parameters: batch_size={batch_size}, learning_rate={learning_rate}, epochs={epochs}')\n",
    "print(\"Training Lake_VAE...\")\n",
    "Optimiser_Lake = torch.optim.Adam(Lake_VAE.parameters(), lr=learning_rate)\n",
    "Trained_Lake_VAE = train_vae(Lake_VAE, trainloader, validationloader, loss_function_lake, Optimiser_Lake, epochs, DEVICE, \"Lake_VAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training only uses 25MiB of GPU memory. Perhaps could try Jupyterlab and jupyterlab-nvdashboard to monitor GPU usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_standard_vae_path = 'best_Standard_VAE_epoch_X.pth'\n",
    "# best_lake_vae_path = 'best_Lake_VAE_epoch_Y.pth'\n",
    "\n",
    "standard_vae_path = 'Standard_VAE_100.pth'\n",
    "lake_vae_path = 'Lake_VAE_100.pth'\n",
    "\n",
    "# Load the best models\n",
    "Standard_VAE = StandardVAE().to(DEVICE)\n",
    "load_model(Standard_VAE, standard_vae_path, DEVICE)\n",
    "\n",
    "Lake_VAE = LakeVAE().to(DEVICE)\n",
    "load_model(Lake_VAE, lake_vae_path, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Trained Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05a8c5785234a80884b02be28cf1a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'text',\n",
       "              'marker': {'color': '#636EFA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '0',\n",
       "              'text': [Label: 0, Pos: (-1.41, 0.01), Label: 0, Pos: (1.59, 1.78),\n",
       "                       Label: 0, Pos: (-0.18, 1.16), ..., Label: 0, Pos: (1.04,\n",
       "                       0.82), Label: 0, Pos: (1.72, 0.51), Label: 0, Pos: (0.08,\n",
       "                       0.60)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '6c9cb993-5bd1-4dd5-a67b-846610daa980',\n",
       "              'x': array([-1.4077994 ,  1.5931716 , -0.1793101 , ...,  1.0437689 ,  1.7170604 ,\n",
       "                           0.08362146], dtype=float32),\n",
       "              'y': array([0.00853138, 1.782689  , 1.1575115 , ..., 0.8239568 , 0.5094191 ,\n",
       "                          0.5986658 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#EF553B', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '1',\n",
       "              'text': [Label: 1, Pos: (-0.20, 0.90), Label: 1, Pos: (-1.00,\n",
       "                       -0.12), Label: 1, Pos: (-0.05, -0.59), ..., Label: 1, Pos:\n",
       "                       (1.32, -0.70), Label: 1, Pos: (0.22, -2.11), Label: 1, Pos:\n",
       "                       (-0.81, -1.38)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '426eefb9-c437-4873-8ed9-7a3883b925fe',\n",
       "              'x': array([-0.20441377, -0.99807054, -0.04572844, ...,  1.3189175 ,  0.21606831,\n",
       "                          -0.8052536 ], dtype=float32),\n",
       "              'y': array([ 0.89914197, -0.12033369, -0.5860829 , ..., -0.7047303 , -2.110897  ,\n",
       "                          -1.383814  ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#00CC96', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '2',\n",
       "              'text': [Label: 2, Pos: (1.69, 0.74), Label: 2, Pos: (-0.66, 0.18),\n",
       "                       Label: 2, Pos: (0.16, -0.15), ..., Label: 2, Pos: (-0.72,\n",
       "                       -1.03), Label: 2, Pos: (0.81, -0.35), Label: 2, Pos: (0.95,\n",
       "                       0.10)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '1ef64994-945e-46f1-9ccc-aaeb7862cb5b',\n",
       "              'x': array([ 1.6913203 , -0.6628243 ,  0.16379195, ..., -0.71985894,  0.81467235,\n",
       "                           0.9523279 ], dtype=float32),\n",
       "              'y': array([ 0.73615843,  0.18042095, -0.15399694, ..., -1.0337013 , -0.34739488,\n",
       "                           0.10293794], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#AB63FA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '3',\n",
       "              'text': [Label: 3, Pos: (-1.50, -0.52), Label: 3, Pos: (-0.83,\n",
       "                       1.40), Label: 3, Pos: (-0.77, 0.72), ..., Label: 3, Pos:\n",
       "                       (-1.13, -0.30), Label: 3, Pos: (-1.58, -0.25), Label: 3,\n",
       "                       Pos: (-1.50, 0.18)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f5b6690f-106a-4aed-afba-ab6569bf96b3',\n",
       "              'x': array([-1.4952697 , -0.8306654 , -0.77317584, ..., -1.1315218 , -1.5830519 ,\n",
       "                          -1.502236  ], dtype=float32),\n",
       "              'y': array([-0.5238146 ,  1.4015245 ,  0.7186393 , ..., -0.30230638, -0.24896108,\n",
       "                           0.1823219 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FFA15A', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '4',\n",
       "              'text': [Label: 4, Pos: (1.84, 1.05), Label: 4, Pos: (1.51, 0.84),\n",
       "                       Label: 4, Pos: (-0.43, 0.22), ..., Label: 4, Pos: (1.28,\n",
       "                       0.84), Label: 4, Pos: (1.94, 2.08), Label: 4, Pos: (1.48,\n",
       "                       -1.84)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '324c3e15-656e-4eac-9420-09c55426bd9a',\n",
       "              'x': array([ 1.8411648 ,  1.5098904 , -0.43428844, ...,  1.2816806 ,  1.9446151 ,\n",
       "                           1.4803433 ], dtype=float32),\n",
       "              'y': array([ 1.0514367 ,  0.83884925,  0.22028992, ...,  0.84332967,  2.0755587 ,\n",
       "                          -1.8397667 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#19D3F3', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '5',\n",
       "              'text': [Label: 5, Pos: (1.34, 0.29), Label: 5, Pos: (0.65, 1.28),\n",
       "                       Label: 5, Pos: (0.48, -2.07), ..., Label: 5, Pos: (-0.33,\n",
       "                       -1.38), Label: 5, Pos: (1.28, -0.61), Label: 5, Pos: (0.15,\n",
       "                       -1.77)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ccd58e53-3dc1-4969-b398-4dc617934bdc',\n",
       "              'x': array([ 1.3401988 ,  0.6506611 ,  0.48460975, ..., -0.33067036,  1.2755812 ,\n",
       "                           0.15120944], dtype=float32),\n",
       "              'y': array([ 0.29330143,  1.2848614 , -2.0694294 , ..., -1.383817  , -0.61366284,\n",
       "                          -1.7726989 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF6692', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '6',\n",
       "              'text': [Label: 6, Pos: (0.69, 0.78), Label: 6, Pos: (-0.80, -0.28),\n",
       "                       Label: 6, Pos: (-1.25, -0.72), ..., Label: 6, Pos: (-0.85,\n",
       "                       0.35), Label: 6, Pos: (-1.36, -0.61), Label: 6, Pos: (-0.64,\n",
       "                       0.96)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f0c960fc-479a-4412-ae8a-b566351052ce',\n",
       "              'x': array([ 0.68854016, -0.79850006, -1.2531973 , ..., -0.85043633, -1.3597162 ,\n",
       "                          -0.63787645], dtype=float32),\n",
       "              'y': array([ 0.7756214 , -0.27642924, -0.7208966 , ...,  0.3489156 , -0.6138962 ,\n",
       "                           0.96468115], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#B6E880', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '7',\n",
       "              'text': [Label: 7, Pos: (-0.16, 0.21), Label: 7, Pos: (1.40, 0.60),\n",
       "                       Label: 7, Pos: (0.56, 0.52), ..., Label: 7, Pos: (1.07,\n",
       "                       0.59), Label: 7, Pos: (0.43, 0.71), Label: 7, Pos: (1.92,\n",
       "                       -0.54)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '6c73749a-dd55-4c89-8451-2d77a871414b',\n",
       "              'x': array([-0.15862869,  1.40012   ,  0.5557944 , ...,  1.0684063 ,  0.42640737,\n",
       "                           1.9221743 ], dtype=float32),\n",
       "              'y': array([ 0.20627311,  0.59566164,  0.51597136, ...,  0.5910313 ,  0.70562536,\n",
       "                          -0.5439225 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF97FF', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '8',\n",
       "              'text': [Label: 8, Pos: (-0.76, -0.08), Label: 8, Pos: (1.15,\n",
       "                       -0.93), Label: 8, Pos: (-0.09, 0.62), ..., Label: 8, Pos:\n",
       "                       (-1.03, 2.31), Label: 8, Pos: (-0.08, -0.51), Label: 8, Pos:\n",
       "                       (-1.88, 2.75)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '103e7255-debe-4848-9dea-776fec01ed20',\n",
       "              'x': array([-0.7627529 ,  1.1474028 , -0.09264461, ..., -1.0322514 , -0.07548898,\n",
       "                          -1.8802145 ], dtype=float32),\n",
       "              'y': array([-0.07716242, -0.93386185,  0.623022  , ...,  2.3085527 , -0.5096066 ,\n",
       "                           2.7514467 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FECB52', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '9',\n",
       "              'text': [Label: 9, Pos: (0.01, -1.74), Label: 9, Pos: (-0.23, 2.14),\n",
       "                       Label: 9, Pos: (-0.01, -0.45), ..., Label: 9, Pos: (2.66,\n",
       "                       -0.53), Label: 9, Pos: (0.12, 0.06), Label: 9, Pos: (0.77,\n",
       "                       -0.29)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '7c60bdee-954e-450e-aaf1-43f58848ca06',\n",
       "              'x': array([ 0.01310484, -0.23344828, -0.01158469, ...,  2.6635933 ,  0.12463351,\n",
       "                           0.77275366], dtype=float32),\n",
       "              'y': array([-1.7429862 ,  2.1443887 , -0.44544402, ..., -0.527765  ,  0.06425001,\n",
       "                          -0.28570086], dtype=float32)}],\n",
       "    'layout': {'height': 600,\n",
       "               'legend': {'title': {'text': 'Digit Label'}},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'layer-constrained VAE Epochs Z Latent Space Visualization of Training Data'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'range': [-6.0744948387146, 8.761572360992432], 'title': {'text': 'Principal Component 1'}},\n",
       "               'yaxis': {'range': [-6.034829139709473, 7.13572883605957], 'title': {'text': 'Principal Component 2'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c5a37fdc8b4d3caabecc8d435d8941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'text',\n",
       "              'marker': {'color': '#636EFA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '0',\n",
       "              'text': [Label: 0, Pos: (3.24, -0.62), Label: 0, Pos: (3.75, -0.23),\n",
       "                       Label: 0, Pos: (5.48, 3.37), ..., Label: 0, Pos: (5.38,\n",
       "                       -0.37), Label: 0, Pos: (5.37, -1.22), Label: 0, Pos: (2.30,\n",
       "                       -1.11)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '69014c68-7810-449a-9489-e59412fbe529',\n",
       "              'x': array([3.2376044, 3.751445 , 5.478574 , ..., 5.37807  , 5.365594 , 2.2957044],\n",
       "                         dtype=float32),\n",
       "              'y': array([-0.6173879 , -0.23114476,  3.367179  , ..., -0.36647964, -1.2212623 ,\n",
       "                          -1.1121862 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#EF553B', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '1',\n",
       "              'text': [Label: 1, Pos: (-4.36, -0.72), Label: 1, Pos: (-4.11,\n",
       "                       -0.69), Label: 1, Pos: (-3.93, -1.35), ..., Label: 1, Pos:\n",
       "                       (-2.94, -3.91), Label: 1, Pos: (-3.48, -0.71), Label: 1,\n",
       "                       Pos: (-3.56, -1.01)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '17005637-ef6b-46ef-8535-c4713d01ff1c',\n",
       "              'x': array([-4.3598247, -4.1129766, -3.9315062, ..., -2.9378192, -3.483702 ,\n",
       "                          -3.5648944], dtype=float32),\n",
       "              'y': array([-0.7222073 , -0.69277436, -1.3541385 , ..., -3.9065282 , -0.707529  ,\n",
       "                          -1.0100542 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#00CC96', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '2',\n",
       "              'text': [Label: 2, Pos: (0.75, -2.45), Label: 2, Pos: (0.86, 0.04),\n",
       "                       Label: 2, Pos: (0.89, -0.51), ..., Label: 2, Pos: (0.46,\n",
       "                       -1.21), Label: 2, Pos: (1.63, -2.27), Label: 2, Pos: (-1.56,\n",
       "                       -0.19)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '9dadfd73-080c-4851-82f6-8371d9853f34',\n",
       "              'x': array([ 0.74585843,  0.85745186,  0.8918636 , ...,  0.46403077,  1.632853  ,\n",
       "                          -1.5626109 ], dtype=float32),\n",
       "              'y': array([-2.4450634 ,  0.03676711, -0.51380724, ..., -1.2067859 , -2.2682905 ,\n",
       "                          -0.18660736], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#AB63FA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '3',\n",
       "              'text': [Label: 3, Pos: (2.06, 0.15), Label: 3, Pos: (1.78, -0.44),\n",
       "                       Label: 3, Pos: (3.11, -0.33), ..., Label: 3, Pos: (2.24,\n",
       "                       0.33), Label: 3, Pos: (2.49, -1.59), Label: 3, Pos: (2.76,\n",
       "                       -2.09)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '05e3772f-da3d-4847-908b-72b1005ace92',\n",
       "              'x': array([2.063074 , 1.777067 , 3.1069233, ..., 2.2407355, 2.488598 , 2.7619631],\n",
       "                         dtype=float32),\n",
       "              'y': array([ 0.14635625, -0.44488013, -0.32702413, ...,  0.32686773, -1.5894037 ,\n",
       "                          -2.091678  ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FFA15A', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '4',\n",
       "              'text': [Label: 4, Pos: (-1.34, -1.74), Label: 4, Pos: (-1.71,\n",
       "                       0.93), Label: 4, Pos: (-1.87, 0.23), ..., Label: 4, Pos:\n",
       "                       (-2.94, 0.02), Label: 4, Pos: (-1.07, 4.13), Label: 4, Pos:\n",
       "                       (-2.01, 0.46)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f1c16ab2-a5d4-4737-b23b-a3313663c0d4',\n",
       "              'x': array([-1.3370727, -1.7125899, -1.8666457, ..., -2.9426525, -1.0707347,\n",
       "                          -2.0093591], dtype=float32),\n",
       "              'y': array([-1.7420241 ,  0.92982584,  0.22629544, ...,  0.01593361,  4.1334844 ,\n",
       "                           0.45747042], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#19D3F3', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '5',\n",
       "              'text': [Label: 5, Pos: (-0.82, -1.72), Label: 5, Pos: (3.15, 1.96),\n",
       "                       Label: 5, Pos: (0.31, -2.96), ..., Label: 5, Pos: (-0.63,\n",
       "                       -2.41), Label: 5, Pos: (0.24, -3.16), Label: 5, Pos: (-1.04,\n",
       "                       -4.74)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bb545f33-9a31-4172-b6b1-f2542a83f8c5',\n",
       "              'x': array([-0.82022744,  3.1469085 ,  0.31351838, ..., -0.6304424 ,  0.23947546,\n",
       "                          -1.0435622 ], dtype=float32),\n",
       "              'y': array([-1.7216672,  1.9634882, -2.956541 , ..., -2.4089675, -3.1610196,\n",
       "                          -4.741926 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF6692', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '6',\n",
       "              'text': [Label: 6, Pos: (2.31, 1.11), Label: 6, Pos: (1.11, -0.21),\n",
       "                       Label: 6, Pos: (-1.30, 1.21), ..., Label: 6, Pos: (0.72,\n",
       "                       -0.20), Label: 6, Pos: (-0.47, 0.78), Label: 6, Pos: (0.05,\n",
       "                       0.08)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '35c454ef-d5d0-4e0c-ad8c-a28d398a698c',\n",
       "              'x': array([ 2.3059537 ,  1.1063657 , -1.2954154 , ...,  0.72169346, -0.4716189 ,\n",
       "                           0.05219045], dtype=float32),\n",
       "              'y': array([ 1.110288  , -0.20573504,  1.2088469 , ..., -0.19573413,  0.77986217,\n",
       "                           0.08063988], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#B6E880', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '7',\n",
       "              'text': [Label: 7, Pos: (-0.74, 1.54), Label: 7, Pos: (-1.46,\n",
       "                       -2.06), Label: 7, Pos: (-1.60, 2.15), ..., Label: 7, Pos:\n",
       "                       (-1.38, 0.83), Label: 7, Pos: (-1.04, 1.27), Label: 7, Pos:\n",
       "                       (-0.75, 0.02)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '06db4150-bcc3-44ed-b780-a4bbce11ad1a',\n",
       "              'x': array([-0.74057126, -1.4603678 , -1.5973274 , ..., -1.3770602 , -1.040419  ,\n",
       "                          -0.7514579 ], dtype=float32),\n",
       "              'y': array([ 1.5362915 , -2.0570478 ,  2.14986   , ...,  0.825302  ,  1.2696224 ,\n",
       "                           0.01755516], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF97FF', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '8',\n",
       "              'text': [Label: 8, Pos: (-1.21, -1.28), Label: 8, Pos: (0.06,\n",
       "                       -1.53), Label: 8, Pos: (1.30, 1.70), ..., Label: 8, Pos:\n",
       "                       (0.52, 3.76), Label: 8, Pos: (1.48, 0.07), Label: 8, Pos:\n",
       "                       (3.39, 1.48)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '354c83f4-a0cc-44b2-9984-0d4ee1e0504f',\n",
       "              'x': array([-1.2091702 ,  0.06246496,  1.303892  , ...,  0.51614815,  1.479412  ,\n",
       "                           3.3893256 ], dtype=float32),\n",
       "              'y': array([-1.2758526 , -1.5311718 ,  1.6970106 , ...,  3.7594926 ,  0.07099034,\n",
       "                           1.484095  ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FECB52', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '9',\n",
       "              'text': [Label: 9, Pos: (-1.53, -1.47), Label: 9, Pos: (-0.90,\n",
       "                       2.77), Label: 9, Pos: (-0.83, 1.51), ..., Label: 9, Pos:\n",
       "                       (0.23, -0.30), Label: 9, Pos: (-0.23, 1.11), Label: 9, Pos:\n",
       "                       (-0.93, -0.42)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '738d2a0e-5ab1-4b21-a527-28b52ec5ba0f',\n",
       "              'x': array([-1.5306681 , -0.90127426, -0.82871085, ...,  0.23162784, -0.23399696,\n",
       "                          -0.9290178 ], dtype=float32),\n",
       "              'y': array([-1.4665556 ,  2.7716835 ,  1.5059083 , ..., -0.30299875,  1.1119274 ,\n",
       "                          -0.4175089 ], dtype=float32)}],\n",
       "    'layout': {'height': 600,\n",
       "               'legend': {'title': {'text': 'Digit Label'}},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'layer-constrained VAE Epochs W Latent Space Visualization of Training Data'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'range': [-6.0744948387146, 8.761572360992432], 'title': {'text': 'Principal Component 1'}},\n",
       "               'yaxis': {'range': [-6.034829139709473, 7.13572883605957], 'title': {'text': 'Principal Component 2'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is_processing = False\n",
    "\n",
    "def reconstruct_from_latent_space(model, latent_point, pca, device):\n",
    "    original_latent = pca.inverse_transform([latent_point])\n",
    "    original_latent_tensor = torch.from_numpy(original_latent).float().to(device)\n",
    "    reconstructed_img = model.decode(original_latent_tensor).cpu()\n",
    "    return reconstructed_img[0].squeeze()\n",
    "\n",
    "def plot_latent_space_interactive(model, data_loader, device, vaename, dataname, num_samples=1000):\n",
    "    ### Calculate and store the latents w and z on the given dataloader\n",
    "    model.eval()\n",
    "    z_latents, w_latents = [], []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            _, z, _, _, _, _, w, _, _, _ = model(data)\n",
    "            # from 'return recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out'\n",
    "            z_latents.append(z.cpu().numpy())\n",
    "            w_latents.append(w.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            if len(z_latents) * data_loader.batch_size > num_samples:\n",
    "                break\n",
    "\n",
    "    z_latents = np.concatenate(z_latents, axis=0)[:num_samples]\n",
    "    w_latents = np.concatenate(w_latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    ###\n",
    "\n",
    "    ### Separate PCAs for z and w\n",
    "    z_pca = PCA(n_components=2)\n",
    "    w_pca = PCA(n_components=2)\n",
    "    z_latents_reduced = z_pca.fit_transform(z_latents)\n",
    "    w_latents_reduced = w_pca.fit_transform(w_latents)\n",
    "\n",
    "    ### Defining colour scales for the MNIST digits, as well as the plotting ranges\n",
    "    custom_color_scale = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A',\n",
    "                          '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52']\n",
    "\n",
    "    # Calculate combined ranges for x and y axes\n",
    "    combined_x_min = min(z_latents_reduced[:, 0].min(), w_latents_reduced[:, 0].min())\n",
    "    combined_x_max = max(z_latents_reduced[:, 0].max(), w_latents_reduced[:, 0].max())\n",
    "    combined_y_min = min(z_latents_reduced[:, 1].min(), w_latents_reduced[:, 1].min())\n",
    "    combined_y_max = max(z_latents_reduced[:, 1].max(), w_latents_reduced[:, 1].max())\n",
    "\n",
    "    # Increase range slightly for aesthetics\n",
    "    x_range = [combined_x_min - 1, combined_x_max + 1]\n",
    "    y_range = [combined_y_min - 1, combined_y_max + 1]\n",
    "    ###\n",
    "\n",
    "    # Function to create the hovertext for the points\n",
    "    def create_traces(latents_reduced):\n",
    "        traces = []\n",
    "        for digit in range(10):\n",
    "            digit_indices = np.where(labels == digit)[0]\n",
    "            trace = go.Scatter(\n",
    "                x=latents_reduced[digit_indices, 0], y=latents_reduced[digit_indices, 1],\n",
    "                mode='markers', marker=dict(color=custom_color_scale[digit], size=10),\n",
    "                name=str(digit),\n",
    "                hoverinfo='text',\n",
    "                text=[f'Label: {digit}, Pos: ({x:.2f}, {y:.2f})' for x, y in latents_reduced[digit_indices]]\n",
    "            )\n",
    "            traces.append(trace)\n",
    "        return traces\n",
    "\n",
    "    z_traces = create_traces(z_latents_reduced)\n",
    "    w_traces = create_traces(w_latents_reduced)\n",
    "\n",
    "    z_fig = go.FigureWidget(z_traces)\n",
    "    z_fig.update_layout(\n",
    "        title=f'{vaename} Z Latent Space Visualization of {dataname} Data',\n",
    "        xaxis_title='Principal Component 1',\n",
    "        yaxis_title='Principal Component 2',\n",
    "        width=800, height=600,\n",
    "        legend_title_text='Digit Label',\n",
    "        xaxis=dict(range=x_range),\n",
    "        yaxis=dict(range=y_range)\n",
    "    )\n",
    "\n",
    "    w_fig = go.FigureWidget(w_traces)\n",
    "    w_fig.update_layout(\n",
    "        title=f'{vaename} W Latent Space Visualization of {dataname} Data',\n",
    "        xaxis_title='Principal Component 1',\n",
    "        yaxis_title='Principal Component 2',\n",
    "        width=800, height=600,\n",
    "        legend_title_text='Digit Label',\n",
    "        xaxis=dict(range=x_range),\n",
    "        yaxis=dict(range=y_range)\n",
    "    )\n",
    "\n",
    "    def update_image(trace, points, selector):\n",
    "        global is_processing\n",
    "        if is_processing:\n",
    "            return\n",
    "\n",
    "        is_processing = True\n",
    "\n",
    "        # If a point is clicked in w or z, the image should be reconstructed from z\n",
    "        if points.point_inds:\n",
    "            # Select point\n",
    "            idx = points.point_inds[0]\n",
    "            latent_pca = z_pca\n",
    "            latent_point = z_latents_reduced[idx]\n",
    "            latent_point = latent_pca.inverse_transform([latent_point])[0]\n",
    "\n",
    "            # Reconstruct image from z latent and display\n",
    "            img = reconstruct_from_latent_space(model, latent_point, latent_pca, device)\n",
    "            plt.imshow(img.detach().numpy(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            display(plt.gcf())\n",
    "\n",
    "        is_processing = False\n",
    "\n",
    "    for trace in z_fig.data:\n",
    "        trace.on_click(update_image)\n",
    "\n",
    "    for trace in w_fig.data:\n",
    "        trace.on_click(update_image)\n",
    "\n",
    "    display(z_fig)\n",
    "    display(w_fig)\n",
    "    model.train()\n",
    "\n",
    "plot_latent_space_interactive(Lake_VAE, trainloader, DEVICE, 'layer-constrained VAE Epochs', 'Training', num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = {\n",
    "    'Lake_VAE': 'Lake_VAE_19.pth',\n",
    "    'BCE_VAE': 'BCE_VAE_19.pth',\n",
    "    'BCE_KLD_VAE': 'BCE_KLD_VAE_19.pth',\n",
    "    'KLD_VAE': 'KLD_VAE_19.pth',\n",
    "    'lake_BCEH_VAE': 'lake_BCEH_VAE_19.pth',\n",
    "    'lake_LLH_VAE': 'lake_LLH_VAE_19.pth',\n",
    "    'lake_KLDH_VAE': 'lake_KLDH_VAE_19.pth'\n",
    "}\n",
    "\n",
    "# Loop over each model, load it, and plot its latent space\n",
    "for model_name, file_name in model_files.items():\n",
    "    # Create a new model instance\n",
    "    model = LakeVAE().to(DEVICE)\n",
    "    \n",
    "    # Load the trained model\n",
    "    model_path = file_name\n",
    "    load_model(model, model_path, DEVICE)\n",
    "\n",
    "    # Plot the latent space\n",
    "    title = f'{model_name} Latent Space'\n",
    "    plot_latent_space_interactive(model, trainloader, DEVICE, title, 'Training', num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_processing = False\n",
    "\n",
    "def reconstruct_from_latent_space(model, latent_point, pca, device):\n",
    "    original_latent = pca.inverse_transform([latent_point])\n",
    "    original_latent_tensor = torch.from_numpy(original_latent).float().to(device)\n",
    "    reconstructed_img = model.decode(original_latent_tensor).cpu()\n",
    "    return reconstructed_img[0].squeeze()\n",
    "\n",
    "def plot_latent_space_interactive(model, data_loader, device, vaename, dataname, num_samples=1000):\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            # mu, _ = model.encode(data)\n",
    "            _, z, _, _, _, _, w, _, _, _ = model(data)\n",
    "\n",
    "            # latents.append(mu.cpu().numpy())\n",
    "            latents.append(z.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "            if len(latents) * data_loader.batch_size > num_samples:\n",
    "                break\n",
    "\n",
    "    latents = np.concatenate(latents, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    latents_reduced = pca.fit_transform(latents)\n",
    "\n",
    "    # Define a custom color scale (10 different colors for digits 0-9)\n",
    "    custom_color_scale = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A',\n",
    "                          '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52']\n",
    "\n",
    "    # Create traces for each digit with hover text\n",
    "    traces = []\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(labels == digit)[0]\n",
    "        trace = go.Scatter(\n",
    "            x=latents_reduced[digit_indices, 0], y=latents_reduced[digit_indices, 1],\n",
    "            mode='markers', marker=dict(color=custom_color_scale[digit], size=10),\n",
    "            name=str(digit),\n",
    "            hoverinfo='text',\n",
    "            text=[f'Label: {digit}, Pos: ({x:.2f}, {y:.2f})' for x, y in latents_reduced[digit_indices]]\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    # Plotly figure with separate traces\n",
    "    fig = go.FigureWidget(traces)\n",
    "    fig.update_layout(\n",
    "        title=f'{vaename} Latent Space Visualisation of MNIST {dataname} Data',\n",
    "        xaxis_title='Principal Component 1',\n",
    "        yaxis_title='Principal Component 2',\n",
    "        width=800, height=600,\n",
    "        legend_title_text='Digit Label'\n",
    "    )\n",
    "\n",
    "    def update_image(trace, points, selector):\n",
    "        global is_processing\n",
    "        if is_processing:\n",
    "            return\n",
    "    \n",
    "        is_processing = True\n",
    "    \n",
    "        if points.point_inds:\n",
    "            idx = points.point_inds[0]\n",
    "            latent_point = latents_reduced[idx]\n",
    "            img = reconstruct_from_latent_space(model, latent_point, pca, device)\n",
    "            plt.imshow(img.detach().numpy(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            display(plt.gcf())\n",
    "    \n",
    "        is_processing = False\n",
    "\n",
    "    for trace in fig.data:\n",
    "        trace.on_click(update_image)\n",
    "\n",
    "    display(fig)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8725f5f590c43d784eb6ba04e588b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'text',\n",
       "              'marker': {'color': '#636EFA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '0',\n",
       "              'text': [Label: 0, Pos: (-0.63, -0.16), Label: 0, Pos: (-2.32,\n",
       "                       0.95), Label: 0, Pos: (-0.91, 0.18), ..., Label: 0, Pos:\n",
       "                       (-1.47, 0.66), Label: 0, Pos: (-1.68, -0.16), Label: 0, Pos:\n",
       "                       (-2.57, 2.81)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fce30dfa-9dcb-4c08-9ea4-61ef101b415a',\n",
       "              'x': array([-0.63008416, -2.319504  , -0.9125697 , ..., -1.4682524 , -1.6816051 ,\n",
       "                          -2.5716333 ], dtype=float32),\n",
       "              'y': array([-0.16392718,  0.9528617 ,  0.178248  , ...,  0.6630471 , -0.15888448,\n",
       "                           2.8053472 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#EF553B', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '1',\n",
       "              'text': [Label: 1, Pos: (1.49, -1.43), Label: 1, Pos: (1.22, -2.28),\n",
       "                       Label: 1, Pos: (1.56, -1.12), ..., Label: 1, Pos: (0.76,\n",
       "                       -1.73), Label: 1, Pos: (0.54, -1.62), Label: 1, Pos: (1.27,\n",
       "                       -1.70)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '55e6507f-ba58-44f8-bc09-729fb92a2cca',\n",
       "              'x': array([1.4910958 , 1.2233448 , 1.5638754 , ..., 0.7572143 , 0.53750205,\n",
       "                          1.2730328 ], dtype=float32),\n",
       "              'y': array([-1.4267559, -2.280591 , -1.1184998, ..., -1.7305815, -1.6161205,\n",
       "                          -1.7025082], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#00CC96', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '2',\n",
       "              'text': [Label: 2, Pos: (-1.45, -0.49), Label: 2, Pos: (-1.05,\n",
       "                       -0.89), Label: 2, Pos: (-1.00, -1.08), ..., Label: 2, Pos:\n",
       "                       (-1.15, -0.90), Label: 2, Pos: (-1.67, -0.85), Label: 2,\n",
       "                       Pos: (-0.34, -1.08)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '5d13ac65-cf62-4ec4-86d1-fc04cce66517',\n",
       "              'x': array([-1.4454576 , -1.0484685 , -1.0014974 , ..., -1.1489596 , -1.673489  ,\n",
       "                          -0.33808437], dtype=float32),\n",
       "              'y': array([-0.48595133, -0.8851439 , -1.0828725 , ..., -0.8954952 , -0.8489729 ,\n",
       "                          -1.0817038 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#AB63FA', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '3',\n",
       "              'text': [Label: 3, Pos: (0.13, -0.23), Label: 3, Pos: (-0.08,\n",
       "                       -0.37), Label: 3, Pos: (-0.10, -0.64), ..., Label: 3, Pos:\n",
       "                       (-0.48, -0.23), Label: 3, Pos: (-0.17, -0.34), Label: 3,\n",
       "                       Pos: (0.53, 0.79)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ab4e490c-a480-423d-b036-b43aabb8b60b',\n",
       "              'x': array([ 0.12913467, -0.08249227, -0.09617212, ..., -0.48161823, -0.16798753,\n",
       "                           0.53176355], dtype=float32),\n",
       "              'y': array([-0.22573772, -0.3703174 , -0.6368521 , ..., -0.22838153, -0.33912697,\n",
       "                           0.7880143 ], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FFA15A', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '4',\n",
       "              'text': [Label: 4, Pos: (1.15, 1.74), Label: 4, Pos: (1.26, 0.37),\n",
       "                       Label: 4, Pos: (1.88, 1.30), ..., Label: 4, Pos: (0.75,\n",
       "                       0.62), Label: 4, Pos: (0.86, 0.90), Label: 4, Pos: (-0.06,\n",
       "                       0.15)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '7adfb556-5b1c-41a4-a1f7-ecdbe9e20919',\n",
       "              'x': array([ 1.1485654 ,  1.2597505 ,  1.8832643 , ...,  0.74610615,  0.85768193,\n",
       "                          -0.05622172], dtype=float32),\n",
       "              'y': array([1.7406414 , 0.37148747, 1.3001574 , ..., 0.61868674, 0.9000321 ,\n",
       "                          0.15274167], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#19D3F3', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '5',\n",
       "              'text': [Label: 5, Pos: (-0.04, 0.05), Label: 5, Pos: (-0.39,\n",
       "                       -0.12), Label: 5, Pos: (-0.58, 0.81), ..., Label: 5, Pos:\n",
       "                       (-0.36, 0.17), Label: 5, Pos: (-0.17, 0.12), Label: 5, Pos:\n",
       "                       (-0.75, -0.07)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '71672ac3-1b3e-47b5-949c-60de95357d12',\n",
       "              'x': array([-0.03579351, -0.3910778 , -0.5830913 , ..., -0.35526097, -0.16722006,\n",
       "                          -0.74881244], dtype=float32),\n",
       "              'y': array([ 0.05131299, -0.12401181,  0.80531776, ...,  0.16619302,  0.11703786,\n",
       "                          -0.07271454], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF6692', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '6',\n",
       "              'text': [Label: 6, Pos: (-0.60, 0.46), Label: 6, Pos: (-0.20,\n",
       "                       -0.77), Label: 6, Pos: (-0.88, 2.78), ..., Label: 6, Pos:\n",
       "                       (-0.47, 0.95), Label: 6, Pos: (-0.90, 0.58), Label: 6, Pos:\n",
       "                       (-0.59, 0.39)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b14c27e3-cca8-4f9c-9589-a2b19ee778e1',\n",
       "              'x': array([-0.5977495 , -0.20094892, -0.8792445 , ..., -0.46954814, -0.89672536,\n",
       "                          -0.59414744], dtype=float32),\n",
       "              'y': array([ 0.4584702 , -0.76854324,  2.7799067 , ...,  0.95268875,  0.57700026,\n",
       "                           0.39119288], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#B6E880', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '7',\n",
       "              'text': [Label: 7, Pos: (2.24, 2.87), Label: 7, Pos: (2.15, 1.60),\n",
       "                       Label: 7, Pos: (1.86, 0.47), ..., Label: 7, Pos: (0.38,\n",
       "                       -0.68), Label: 7, Pos: (1.54, 0.14), Label: 7, Pos: (1.47,\n",
       "                       0.19)],\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f9919d29-529e-427e-ba85-1debec38f939',\n",
       "              'x': array([2.241482  , 2.151011  , 1.8576628 , ..., 0.37870616, 1.5431622 ,\n",
       "                          1.4716704 ], dtype=float32),\n",
       "              'y': array([ 2.867166  ,  1.5960711 ,  0.47146928, ..., -0.6773984 ,  0.13956228,\n",
       "                           0.19114761], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FF97FF', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '8',\n",
       "              'text': [Label: 8, Pos: (-0.13, -0.36), Label: 8, Pos: (-0.58,\n",
       "                       0.04), Label: 8, Pos: (-0.70, -0.65), ..., Label: 8, Pos:\n",
       "                       (-0.22, -0.43), Label: 8, Pos: (-0.35, -0.51), Label: 8,\n",
       "                       Pos: (-0.17, -0.49)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '33cdfc5b-8cdf-42ed-a9aa-7ebfe8e05591',\n",
       "              'x': array([-0.13157482, -0.5791328 , -0.70384705, ..., -0.21692069, -0.35428002,\n",
       "                          -0.17256823], dtype=float32),\n",
       "              'y': array([-0.3565396 ,  0.03560884, -0.64738625, ..., -0.4315248 , -0.51000136,\n",
       "                          -0.48731732], dtype=float32)},\n",
       "             {'hoverinfo': 'text',\n",
       "              'marker': {'color': '#FECB52', 'size': 10},\n",
       "              'mode': 'markers',\n",
       "              'name': '9',\n",
       "              'text': [Label: 9, Pos: (0.36, -0.42), Label: 9, Pos: (0.46, 0.96),\n",
       "                       Label: 9, Pos: (0.93, 0.66), ..., Label: 9, Pos: (0.98,\n",
       "                       0.59), Label: 9, Pos: (1.33, 0.47), Label: 9, Pos: (0.87,\n",
       "                       0.04)],\n",
       "              'type': 'scatter',\n",
       "              'uid': '21900999-2b3b-43e9-8cc1-0ba2fc2198b2',\n",
       "              'x': array([0.3634028 , 0.46415734, 0.9340558 , ..., 0.9751349 , 1.3297324 ,\n",
       "                          0.8734408 ], dtype=float32),\n",
       "              'y': array([-0.4155665 ,  0.96258146,  0.6563021 , ...,  0.58824784,  0.4674267 ,\n",
       "                           0.04409432], dtype=float32)}],\n",
       "    'layout': {'height': 600,\n",
       "               'legend': {'title': {'text': 'Digit Label'}},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Standard VAE Epochs Latent Space Visualisation of MNIST Training Data'},\n",
       "               'width': 800,\n",
       "               'xaxis': {'title': {'text': 'Principal Component 1'}},\n",
       "               'yaxis': {'title': {'text': 'Principal Component 2'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_latent_space_interactive(Standard_VAE, trainloader, DEVICE, 'Standard VAE Epochs' ,'Training', num_samples=5000)\n",
    "#plot_latent_space_interactive(Standard_VAE, validationloader, DEVICE, 'Standard VAE Epochs' ,'Validation', num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_latent_space_interactive(Lake_VAE, trainloader, DEVICE, 'layer-constrained VAE Epochs', 'Training', num_samples=5000)\n",
    "#plot_latent_space_interactive(Lake_VAE, validationloader, DEVICE, 'layer-constrained VAE Epochs', 'Validiation', num_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Density Estimation Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 900 MNIST validation images (labelled 0) and 100 GAN generated MNIST images (labelled 1) to create a combined testing dataset. \n",
    "Then attempting to see if the LAKE anomaly detection can find the synthetic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of pixel values: 0.0 to 1.0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the validation dataset\n",
    "mnist_validation_data = validation_dataset \n",
    "\n",
    "# Extract MNIST images and labels\n",
    "mnist_images = mnist_validation_data.dataset.data[mnist_validation_data.indices][:900]\n",
    "mnist_labels = torch.zeros(900)  # Label '0' for real MNIST data\n",
    "\n",
    "# Load GAN generated images\n",
    "gan_images_path = 'gan_generated_mnist_images.pt'\n",
    "gan_images = torch.load(gan_images_path)\n",
    "\n",
    "# Normalize the MNIST and GAN images if they are not already\n",
    "mnist_images = mnist_images.float() / 255.0\n",
    "mnist_images = mnist_images[:,None]\n",
    "gan_images = gan_images.float() / 255.0 if gan_images.max() > 1.0 else gan_images\n",
    "\n",
    "# Add a pure white image as an anomaly\n",
    "white_image = torch.ones(1, 1, 28, 28)\n",
    "white_label = torch.tensor([1])  # Anomaly label\n",
    "\n",
    "# Combine MNIST, GAN, and white image into one dataset\n",
    "combined_images = torch.cat((mnist_images, gan_images, white_image), dim=0)\n",
    "combined_labels = torch.cat((mnist_labels, torch.ones(100), white_label), dim=0)\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "combined_dataset = TensorDataset(combined_images, combined_labels)\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Check the normalization\n",
    "max_pixel_value = combined_images.max()\n",
    "min_pixel_value = combined_images.min()\n",
    "print(f\"Range of pixel values: {min_pixel_value} to {max_pixel_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 12)\n",
      "(1001, 12)\n"
     ]
    }
   ],
   "source": [
    "# Function to encode dataset and compute reconstruction errors\n",
    "def encode_and_reconstruct(model, dataloader, device):\n",
    "    model.eval()\n",
    "    ws = []\n",
    "    rec_errors = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            # Get w and x' in forward pass\n",
    "            recon_x, _, _, _, _, _, w, _, _, _ = model(x)\n",
    "\n",
    "            # Store w\n",
    "            ws.append(w.cpu()) \n",
    "\n",
    "            # Calc and store rec_eu and rec_co\n",
    "            rec_euclidean = torch.norm(x - recon_x, p=2, dim=(1, 2, 3))\n",
    "            rec_cosine = F.cosine_similarity(x.view(x.size(0), -1), recon_x.view(recon_x.size(0), -1), dim=1)\n",
    "            r = torch.stack((rec_euclidean, rec_cosine), dim=1)\n",
    "            rec_errors.append(r.cpu()) \n",
    "            \n",
    "    return torch.cat(ws, dim=0), torch.cat(rec_errors, dim=0)\n",
    "    \n",
    "Lake_VAE.to(DEVICE)\n",
    "\n",
    "# For Training Data\n",
    "encoded_ws, reconstruction_rs = encode_and_reconstruct(Lake_VAE, trainloader, DEVICE)\n",
    "assert not torch.isnan(encoded_ws).any(), \"NaNs in encoded_ws\"\n",
    "assert not torch.isnan(reconstruction_rs).any(), \"NaNs in reconstruction_rs\"\n",
    "C_Train = np.hstack((encoded_ws, reconstruction_rs))\n",
    "print(C_Train.shape)\n",
    "\n",
    "# Testing Data\n",
    "encoded_ws, reconstruction_rs = encode_and_reconstruct(Lake_VAE, combined_loader, DEVICE)\n",
    "assert not torch.isnan(encoded_ws).any(), \"NaNs in encoded_ws\"\n",
    "assert not torch.isnan(reconstruction_rs).any(), \"NaNs in reconstruction_rs\"\n",
    "C = np.hstack((encoded_ws, reconstruction_rs))\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main things that affect the anomaly detection results. <br>\n",
    "A. The model used (how well the data is compressed). The ability of your VAE to compress and reconstruct data is critical. It is contained within w and r. <br>\n",
    "B. The KDE's bandwidth setting, corresponding to the smoothness of the density estimate. <br>\n",
    "If it's too narrow, you might have a very bumpy estimate that's sensitive to noise. <br>\n",
    "If it's too wide, the estimate might be too smooth and anomalies could be missed because they blend in with the normal data. <br>\n",
    "C. Anomaly detection threshold. What proportion of your dataset you set expected to be an anomaly. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KernelDensity from sklearn represents fh(s) = (1/n) ∑[i=1 to n] Kh(s - ci)\n",
    "from joblib import dump\n",
    "\n",
    "def perform_kde(C_Train):\n",
    "    # Doing k-fold validation on to find good bandwidth value\n",
    "    params = {'bandwidth': np.linspace(0.01, 0.2, 20)}\n",
    "    grid = GridSearchCV(KernelDensity(kernel='gaussian'), params, cv=5)\n",
    "    grid.fit(C_Train)\n",
    "    print(f\"Optimal bandwidth: {grid.best_estimator_.bandwidth}\")\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=grid.best_estimator_.bandwidth)\n",
    "    \n",
    "    #kde = KernelDensity(kernel='gaussian', bandwidth=0.05) # Manual bandwidth setting\n",
    "    kde.fit(C_Train)\n",
    "    return kde\n",
    "\n",
    "# Function to estimate density from C values\n",
    "def estimate_density(kde, C):\n",
    "    log_density = kde.score_samples(C)\n",
    "    return np.exp(log_density)\n",
    "\n",
    "# Calibrate and Save KDE\n",
    "kde_model = perform_kde(C_Train)\n",
    "dump(kde_model, 'kde_model.joblib')\n",
    "\n",
    "density_estimates = estimate_density(kde_model, C)\n",
    "\n",
    "# Determine anomaly threshold and detect anomalies\n",
    "threshold = np.percentile(density_estimates, 10)\n",
    "anomalies = density_estimates < threshold\n",
    "\n",
    "# Calculate and print anomaly detection results\n",
    "detected_anomalies = np.sum(anomalies[-101:]) \n",
    "print(f\"Detected {detected_anomalies} anomalies out of 101 synthetic images.\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(density_estimates, bins=100, alpha=0.5, color='blue', label='Density Scores')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.title('Density Estimates and Anomaly Threshold')\n",
    "plt.xlabel('Density Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 10 anomalies out of 101 synthetic images.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calibrate and Save KDE\n",
    "from joblib import load\n",
    "kde_model = load('kde_model.joblib')\n",
    "\n",
    "# Function to estimate density from C values\n",
    "def estimate_density(kde, C):\n",
    "    log_density = kde.score_samples(C)\n",
    "    return np.exp(log_density)\n",
    "\n",
    "density_estimates = estimate_density(kde_model, C)\n",
    "\n",
    "# Determine anomaly threshold and detect anomalies\n",
    "threshold = np.percentile(density_estimates, 10)\n",
    "anomalies = density_estimates < threshold\n",
    "\n",
    "# Calculate and print anomaly detection results\n",
    "detected_anomalies = np.sum(anomalies[-101:]) \n",
    "print(f\"Detected {detected_anomalies} anomalies out of 101 synthetic images.\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(density_estimates, bins=100, alpha=0.5, color='blue', label='Density Scores')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.title('Density Estimates and Anomaly Threshold')\n",
    "plt.xlabel('Density Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GPU acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the GPU acceleration properly up on Pytorch for a .ipynb file on Axon. <br>\n",
    "You have to first use nvidia-smi to see an unused GPU,  <br>\n",
    "then use nvidia-smi -L to see its MIG ID, and set it as an environmental variable.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for the CUDA_VISIBLE_DEVICES value\n",
    "cuda_device = input(\"Enter the CUDA_VISIBLE_DEVICES value: \")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cuda_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(\"Is CUDA available:\", is_cuda_available)\n",
    "\n",
    "# Determine the device to use: GPU (CUDA), Apple Silicon (MPS), or CPU\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tensor on CUDA: tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Test tensor operation on GPU\n",
    "    test_tensor = torch.tensor([1.0, 2.0, 3.0], device=\"cuda\")\n",
    "    print(\"Test tensor on CUDA:\", test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully moved a tensor to the device: tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if is_cuda_available:\n",
    "    try:\n",
    "        test_tensor = torch.tensor([1, 2, 3], device=DEVICE)\n",
    "        print(\"Successfully moved a tensor to the device:\", test_tensor)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error moving a tensor to the device:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining VAE classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20, w_dim=10):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder layers\n",
    "        # Input: [bs, 1, 28, 28]\n",
    "        self.enc_conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)  # Output: [bs, 16, 14, 14]\n",
    "        self.enc_conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1) # Output: [bs, 32, 7, 7]\n",
    "        self.enc_fc1 = nn.Linear(32 * 7 * 7, w_dim)  # Output: [bs, 128]\n",
    "        # Two output layers for the latent space\n",
    "        self.enc_fc2 = nn.Linear(w_dim, latent_dim)  # For mu, Output: [bs, latent_dim]\n",
    "        self.enc_fc3 = nn.Linear(w_dim, latent_dim)  # For logvar, Output: [bs, latent_dim]\n",
    "\n",
    "        # Decoder layers\n",
    "        self.dec_fc1 = nn.Linear(latent_dim, w_dim)  # Output: [bs, 128]\n",
    "        self.dec_fc2 = nn.Linear(w_dim, 32 * 7 * 7)  # Output: [bs, 1568]\n",
    "        self.dec_conv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: [bs, 16, 14, 14]\n",
    "        self.dec_conv2 = nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: [bs, 1, 28, 28]\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.enc_conv1(x))\n",
    "        h = F.relu(self.enc_conv2(h))\n",
    "        h = torch.flatten(h, start_dim=1)\n",
    "        h = F.relu(self.enc_fc1(h))\n",
    "        return self.enc_fc2(h), self.enc_fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        # Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.dec_fc1(z)) \n",
    "        h = F.relu(self.dec_fc2(h)).view(-1, 32, 7, 7) # .view reshapes [bs, 1568] to [bs, 32, 7, 7]\n",
    "        h = F.relu(self.dec_conv1(h))\n",
    "        return torch.sigmoid(self.dec_conv2(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder layers\n",
    "        # Input: [bs, 1, 28, 28]\n",
    "        enc_conv1_out = F.relu(self.enc_conv1(x))  # Output: [bs, 16, 14, 14]\n",
    "        enc_conv2_out = F.relu(self.enc_conv2(enc_conv1_out))  # Output: [bs, 32, 7, 7]\n",
    "        flattened = torch.flatten(enc_conv2_out, start_dim=1)  # Output: [bs, 1568]\n",
    "        \n",
    "        # w = F.relu(self.enc_fc1(flattened))  # Output: [bs, 128] # Eqn (5) in LAKE paper\n",
    "        w = self.enc_fc1(flattened)  # Not sure if relu is used in the paper or not. Output: [bs, 128] # Eqn (5) in LAKE paper\n",
    "        \n",
    "        mu, logvar = self.enc_fc2(w), self.enc_fc3(w)  # Output: [bs, latent_dim], [bs, latent_dim] # Eqn (6) in LAKE paper\n",
    "\n",
    "        # Reparameterization and Decoding layers\n",
    "        z = self.reparameterize(mu, logvar)  # Output: [bs, latent_dim] # Eqn (7) in LAKE paper\n",
    "        dec_fc1_out = F.relu(self.dec_fc1(z))  # Output: [bs, 128]\n",
    "        dec_fc2_out = F.relu(self.dec_fc2(dec_fc1_out)).view(-1, 32, 7, 7)  # Output: [bs, 1568], then reshaped to [bs, 32, 7, 7]\n",
    "        dec_conv1_out = F.relu(self.dec_conv1(dec_fc2_out))  # Output: [bs, 16, 14, 14]\n",
    "        recon_x = torch.sigmoid(self.dec_conv2(dec_conv1_out))  # Output: [bs, 1, 28, 28]\n",
    "\n",
    "        return recon_x, z, mu, logvar, enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, z, mu, logvar, x, layer_loss_weight=0, intermediate_layers=None):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    layer_loss = 0\n",
    "    if layer_loss_weight > 0 and intermediate_layers is not None:\n",
    "        enc_conv1_out, enc_conv2_out, w, dec_fc1_out, dec_fc2_out, dec_conv1_out = intermediate_layers\n",
    "        layer_loss = F.mse_loss(enc_conv1_out, dec_conv1_out) + F.mse_loss(enc_conv2_out, dec_fc2_out) + F.mse_loss(w, dec_fc1_out)\n",
    "\n",
    "    return BCE + KLD + layer_loss_weight * layer_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Splitting the dataset into train and validation sets\n",
    "train_size = int(0.8 * len(mnist_trainset))\n",
    "validation_size = len(mnist_trainset) - train_size\n",
    "train_dataset, validation_dataset = random_split(mnist_trainset, [train_size, validation_size])\n",
    "\n",
    "# Download and load the test data\n",
    "test_dataset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "validationloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "Standard_VAE = VAE().to(DEVICE)\n",
    "Lake_VAE = VAE().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from wandb) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from wandb) (5.9.6)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.35.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from wandb) (53.0.0)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from wandb) (4.8.0)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.15.0 (from wandb)\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/msxaj10/Documents/LAKE/.venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.35.0-py2.py3-none-any.whl (248 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.40 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 protobuf-4.25.1 sentry-sdk-1.35.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/msxaj10/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mexiomius\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/msxaj10/Documents/LAKE/Cardiotocography/wandb/run-20231120_125716-d785dt8j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/exiomius/vae_mnist/runs/d785dt8j' target=\"_blank\">swept-moon-1</a></strong> to <a href='https://wandb.ai/exiomius/vae_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/exiomius/vae_mnist' target=\"_blank\">https://wandb.ai/exiomius/vae_mnist</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/exiomius/vae_mnist/runs/d785dt8j' target=\"_blank\">https://wandb.ai/exiomius/vae_mnist/runs/d785dt8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'bce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/msxaj10/Documents/LAKE/Cardiotocography/MNIST-LAKE-3.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baxon.nottingham.ac.uk/home/msxaj10/Documents/LAKE/Cardiotocography/MNIST-LAKE-3.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(recon_x, z, mu, logvar, x, wandb\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlayer_loss_weight, intermediate_layers)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baxon.nottingham.ac.uk/home/msxaj10/Documents/LAKE/Cardiotocography/MNIST-LAKE-3.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Extract individual loss components\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baxon.nottingham.ac.uk/home/msxaj10/Documents/LAKE/Cardiotocography/MNIST-LAKE-3.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m bce, kld, layer_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mbce, loss\u001b[39m.\u001b[39mkld, loss\u001b[39m.\u001b[39mlayer_loss\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baxon.nottingham.ac.uk/home/msxaj10/Documents/LAKE/Cardiotocography/MNIST-LAKE-3.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Backward pass and optimize\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baxon.nottingham.ac.uk/home/msxaj10/Documents/LAKE/Cardiotocography/MNIST-LAKE-3.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'bce'"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize images\n",
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images.detach()[:nmax], nrow=8).permute(1, 2, 0))\n",
    "\n",
    "def visualize_reconstruction(model, device, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(data_loader):\n",
    "            x = x.to(device)\n",
    "            recon_x, _, _, _ = model(x)\n",
    "            if i == 0:  # Only visualize for the first batch\n",
    "                return recon_x\n",
    "\n",
    "# Initialize a W&B run\n",
    "wandb.init(project='vae_mnist', entity='exiomius', config={\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 50,\n",
    "    'batch_size': 64,\n",
    "    'latent_dim': 20,\n",
    "    'layer_loss_weight': 0  # Set to >0 for Lake VAE\n",
    "})\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=wandb.config.batch_size)\n",
    "\n",
    "# Initialize the VAE model\n",
    "model = VAE(latent_dim=wandb.config.latent_dim)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(wandb.config.epochs):\n",
    "    model.train()\n",
    "    train_loss, train_bce, train_kld, train_layer_loss = 0, 0, 0, 0\n",
    "    for x, _ in train_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        recon_x, z, mu, logvar, *intermediate_layers = model(x)\n",
    "\n",
    "        # Compute loss using the loss function\n",
    "        loss = loss_function(recon_x, z, mu, logvar, x, wandb.config.layer_loss_weight, intermediate_layers)\n",
    "\n",
    "        # Extract individual loss components\n",
    "        bce, kld, layer_loss = loss.bce, loss.kld, loss.layer_loss\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_bce += bce.item()\n",
    "        train_kld += kld.item()\n",
    "        train_layer_loss += layer_loss\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_bce, val_kld, val_layer_loss = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, _ in val_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            recon_x, z, mu, logvar, *intermediate_layers = model(x)\n",
    "            loss = loss_function(recon_x, z, mu, logvar, x, wandb.config.layer_loss_weight, intermediate_layers)\n",
    "            bce, kld, layer_loss = loss.bce, loss.kld, loss.layer_loss\n",
    "            val_loss += loss.item()\n",
    "            val_bce += bce.item()\n",
    "            val_kld += kld.item()\n",
    "            val_layer_loss += layer_loss\n",
    "\n",
    "    # Visualize reconstructed images\n",
    "    recon_images = visualize_reconstruction(model, DEVICE, val_loader)\n",
    "    wandb.log({'recon_images': [wandb.Image(recon_images.cpu(), caption='Reconstructed Images')]})\n",
    "\n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        'train_loss': train_loss / len(train_loader.dataset),\n",
    "        'train_bce': train_bce / len(train_loader.dataset),\n",
    "        'train_kld': train_kld / len(train_loader.dataset),\n",
    "        'train_layer_loss': train_layer_loss / len(train_loader.dataset),\n",
    "        'val_loss': val_loss / len(val_loader.dataset),\n",
    "        'val_bce': val_bce / len(val_loader.dataset),\n",
    "        'val_kld': val_kld / len(val_loader.dataset),\n",
    "        'val_layer_loss': val_layer_loss / len(val_loader.dataset),\n",
    "        'epoch': epoch\n",
    "    })\n",
    "\n",
    "    # Optional: Save model checkpoints\n",
    "    # torch.save(model.state_dict(), 'model_checkpoint.pth')\n",
    "\n",
    "# Close the W&B run\n",
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
